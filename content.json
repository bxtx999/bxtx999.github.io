{"pages":[{"title":"","text":"","link":"/404.html"},{"title":"about","text":"姓名： Hu 邮箱： me(at)hoooo(dot)org","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"search","text":"","link":"/search/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"DSL 思考","text":"一、什么是DSL DSL，即Domain Specific Language，是为在某些特定领域内解决特定问题而设计的专用语言，其基本思想是“求专不求全”。DSL主要目的是消除代码复杂度和间接性，并且应该注重专业领域。此外，也需要合理恰当的语法形式来实现DSL。 DSL 的类型： 非计算 HTML、CSS 计算能力有限 SQL、 CPP templates 、正则表达式 异构 GLSL 特殊应用 Matlab 二、 Embedded DSL Embedded domain-specific language（eDSL）是嵌入式DSL，其优势是利用宿主语言实现。嵌入式DSL可以看做是库，API can usefully be thought of as a language。 Embedding DSL 利用宿主语言的现有api实现，不再需要编写解析器。 实现 eDSL 的方式有如下几种： 字符串 是最简单的实现方式，因为不需要编写解析器。最好的例子是在JQuery中检索CSS 1const myTable = $(&quot;#foo div.tabular-data table); CSS选择器是只是指定一组HTML document 元素的DSL。 同样，还有正则表达式。 1const matches = input.match(&quot;.*/.+\\\\.png$&quot;); 宏定义、准引用(Quasiquotation) 宏定义（Macros）能够在编译时期执行代码。宏常常与准引用一起使用，比如在Lisp和 Haskell 中可以自定义语法。 在Yesod 网络框架中，Haskell 有 Shakespearean Templates 的例子，允许HTML/CSS/JS代码在Haskell 代码中插值。 123456789101112131415data Person = Person { name :: String , age :: Int }main :: IO ()main = putStrLn $ renderHtml [shamlet|&lt;p&gt;Hello, my name is #{name person} and I am #{show $ age person}.&lt;p&gt; Let&apos;s do some funny stuff with my name: # &lt;b&gt;#{sort $ map toLower (name person)}&lt;p&gt;Oh, and in 5 years I&apos;ll be #{show ((+) 5 (age person))} years old.|] where person = Person &quot;Michael&quot; 26 组合Combinators Combinators 是利用小函数或者对象进行构建，因为没有自定义语法，所以很像 API。 例如，Ruby的Rake构建系统对.md文件运行pandoc生成.html文件。 123456task :default =&gt; :htmltask :html =&gt; %W[ch1.html ch2.html ch3.html]rule &quot;.html&quot; =&gt; &quot;.md&quot; do |t| sh &quot;pandoc -o #{http://t.name} #{t.source}&quot;end Monads 在Haskell 中可以利用 Monad 来实现 eDSL。 12345result = do a &lt;- [1..10] b &lt;- [1..10] guard (a /= b) guard (a + b == 7) return (a, b) eDSL 因为能够用于处理专用领域中的问题，所以用处极大。但是在DSL设计和使用中，应该注重在实现上使用恰当的语法。同时，对于DSL解决的问题可能是“动态逻辑加载”，可以使用现有语言动态调用解析器来完成。 库（library）和 eDSL 很相似，有时候最简单的库就能够解决问题。 Embedded DSLs are useful because they let us apply everything we know about programming languages to specific domains. 参考 What is an embedded domain-specific language? 王垠——DSL Embedded Domain Specific Language 领域专用语言迷思 DSL在实际工作中的应用","link":"/2018/07/17/DSL/"},{"title":"Image processing using Graph_1","text":"Lecture1 Graph-based methods in Image Processing for: Segmentation 图像分割 Filtering 过滤 Classification and clustering 聚类/分类 We will sometimes regard a picture as being a real-valued, non-negative function of two real variables; the value of this function at a point will be called the gray-level of the picture at the point. —— Rosenfeld Storing the image in a computer requires digitization, 图片存储： Sampling(recoding image values at a finite set of samples points) Quantization(discretizing the continuous functions values) Typically, sampling points are located on a Cartesian grid. Basic model Generalized image modalities( multispectral images) Generalized image domains(video, volume images MRI) Generalized sampling point distributions( non-Cartesian girds) 形态、样式、采用方法 Benefit for image processing Discrete and mathematically simple representation that lends itself well to the development of efficient and provably correct methods. A minimalistic image representation – flexibility in representing different types of images. re-use existing algorithms and theorems for image analysis! Image as Graphs Graph based image processing methods typically operate on pixel adjacency graphs graphs whose vertex set is the set of image elements, whose edge set is given by an adjacency relation on the image elements Graph segmentation To segment an image represented as a graph, we want to partition the graph into a number of separate connected components. The partitioning can be described either as a vertex labeling or as a graph cut. Graph partitioning vertex labeling Vertex labeling associates each node of the graph with an element in some set of labels. Each element in this set represents an object category. graph cuts A cut is a set of edges that, if they are removed from a graph, separates the graph into two or more connected components. References Space-Variant Machine Vision — A Graph Theoretic Approach. A graph-based framework for sub-pixel image segmentation.","link":"/2017/12/21/Graph_1/"},{"title":"Image processing using Graph_2","text":"L2 体素或立体像素(voxel) 是体积像素(volume pixel) 的简称，是数字数据位于三维空间分区的最小单位，应用于三维成像、科学数据与医疗视频等领域。 CPP —— Boost Graph libraries Matlab —— Graph Analysis toolbox 适定问题 well-posted problem 不适定问题 ill-posted problem Image segmentation 是不适定问题，除非我们限定分割对象。 image segmentation: 在医学领域中，图像分割是病变区域提取、特定组织测量以及实现三维重建的基础。 Recognition （识别） the task of roughly determining where in the image an object is located， 即确定目标物体的大概位置并区别于图像中的其他物体。 Delineation （描绘） the task of determining the exact extent of the object，即在于精确定义和刻画图像中目标物体的区域或者边缘的空间范围。 ​","link":"/2017/12/27/Graph_2/"},{"title":"Pin学习1","text":"什么是插桩（Instrumentation）? 向程序注入额外的代码来收集程序运行时的状态。 插桩（Instrumentation）的方法： * 源代码插桩（source instrumentation） ——对源码进行操作 * 二进制插桩（Binary instrumentation） ——运行时直接注入 为何使用动态指令注入？ 不需要重新编译或重新链接 在运行时检测代码 处理动态生成的代码 附加到运行的进程中 Pin工具的有点 简单易用 使用动态指令插入方式 —— 不需要修改源代码、重新编译、重新连接 多平台支持 支持X86、X86_64、Itanium、Xscale 支持Linux、Windows、MacOS 鲁棒性 支持现实常见应用： 数据库、浏览器 支持多线程程序 支持信号(signals) 高效 适用编辑器优化(Applies compiler optimizations on instrumentation code) Pin使用方式 1234567// 加载和注入一个程序$ pin -t pintool -- application// Pin —— 注入引擎，在kit中已经提供//Pintool —— 注入工具，自己编写或者适用kit中提供的// 注入到一个程序中（进程号）$ pin -t pintool -pid 1234 Pin注入的API 架构无关的基础API： 提供确定的基础功能的API Control-flow changes Memory accesses 基于特定架构的API： 如基于IA32的段寄存器信息 基于调用（call-based）的API： 桩程序（Instrumentation routines） 分析程序（Analysis routines） 桩程序和分析程序的区别 桩和分析都是从ATOM工具发展来的概念。（搜索关键字 ATOM analysis Instrumentation ） &gt; ATOM，即Analysis Tools with OM， http://atominstrument.com/products-services-overview/ http://www.hpl.hp.com/techreports/Compaq-DEC/WRL-TN-44.pdf 桩程序(instrumentation routines）定义了在哪里插桩； * 如在指令前 ： 在指令第一次执行时插桩 分析程序（analysis routines）定义当桩启动时执行哪些操作。 * 如 增量计数器： 在每一次指令执行时发生 Pintool举例1——指令计数 12345678910sub $0xff, %edx counter++;cmp %esi, %edx counter++;jle &lt;L1&gt; counter++;mov $0x1, %edi counter++;add $0x10, %eax counter++; 输出指令数 1234567$ /bin/lsMakefile imageload.out itrace proccountimageload inscount0 atrace itrace.out$ pin -t inscount0 -- /bin/lsMakefile imageload.out itrace proccountimageload inscount0 atrace itrace.outCount 422838 输出指令数 Pintool举例2——指令跟踪 123456789101112// 传递ip参数到分析程序中Print(ip); sub $0xff, %edx Print(ip); sub $0xff, %edx Print(ip); jle &lt;L1&gt;Print(ip); mov $0x1, %ediPrint(ip); add $0x10, %eaxPrint(ip); 输出轨迹 12345678910$ pin -t itrace -- /bin/lsMakefile imageload.out itrace proccountimageload inscount0 atrace itrace.out$ head -6 itrace.out0x7f20e459b2d00x7f20e459b2d30x7f20e459ea400x7f20e459ea410x7f20e459ea440x7f20e459ea46 ManualExamples/itrace.cpp 12345678910111213141516#include &lt;stdio.h&gt;#include &quot;pin.H&quot;FILE * trace;void printip(void *ip) { fprintf(trace, &quot;%p\\n&quot;, ip); } // 分析程序void Instruction(INS ins, void *v) {INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR)printip, IARG_INST_PTR, IARG_END);} // 插桩程序void Fini(INT32 code, void *v) { fclose(trace); }int main(int argc, char * argv[]) {trace = fopen(&quot;itrace.out&quot;, &quot;w&quot;);PIN_Init(argc, argv);INS_AddInstrumentFunction(Instruction, 0);PIN_AddFiniFunction(Fini, 0);PIN_StartProgram();return 0;} 分析程序的参数举例： IARG_INST_PTR 指令指针值（program counter） IARG_UINT32 整型值 IARG_REG_VALUE 指定寄存器的值 IARG_BRANCH_TARGET_ADDR 分支桩的目标地址 IARG_MEMORY_READ_EA 内存读取的有效地址 一个指令的桩的位置 前置（IPOINT_BEFORE） 后置 Fall-through edge（IPOINT_AFTER） Taken edge （IPOINT_TAKEN_BRANCH） 注： 红色代表 IPOINT_BEFORE， 绿色代表 IPOINT_AFTER，黑色代表 IPOINT_TAKEN_BRANCH。 来源 http://www.cs.du.edu/~dconnors/courses/comp3361/notes/PinTutorial 参考 http://terenceli.github.io/技术/2014/01/02/intro-to-pin http://huirong.github.io/2015/12/30/Intel-Pin-introduction/#参考文献","link":"/2016/11/16/Pin%E5%AD%A6%E4%B9%A01/"},{"title":"Social computing 1 —— 网络与市场中的计算思维","text":"1. 网络与图论 图是网络结构信息的抽象，表达的是网络中各种事物之间的关系。 一个简单图是集合 X=(V,E)X = (V, E)X=(V,E)，其中 VVV 是定点， EEE 是边。一条边连接的两个顶点称为它的两端点。其实我们可以把一条边看作 VVV 的子集，其中有两个顶点。一个简单图就是一个无向图，它不会有圈或者重边。若 u≠vu \\not = vu​=v 是两个顶点， u,v{u, v}u,v 是一条边，那么两顶点相邻，记为 u,v{u, v}u,v。 同一个图，可能有多种不同的画法。也就是说，同一个图可能呈现出不同的图像形式。 同构图 在图论中，假设 G=(V,E)G=(V, E)G=(V,E) 和 G1=(V1,E1)G1 = (V1, E1)G1=(V1,E1)，如果存在一个双射 m:V→V1m: V → V1m:V→V1 ，使得对所有的 x,y∈Vx, y ∈ Vx,y∈V 均有 xy∈Exy ∈ Exy∈E 等价于 m(x)m(y)∈E1m(x)m(y)∈ E1m(x)m(y)∈E1，则称 GGG 和 G1G1G1 是同构的，这样的一个映射 mmm 称之为同构，如果 G=G1G = G1G=G1，则称他们为一个自同构。 路径（walk） 一个长度为 kkk 的路径是一个费控的顶点和边的交错序列 v0e0v1e1...ek−1vkv_0e_0v_1e_1...e_{k-1}v_kv0​e0​v1​e1​...ek−1​vk​ ，使得对于所有 i&lt;ki &lt; ki&lt;k 均有 ei=vivi+1e_i = v_iv_{i+1}ei​=vi​vi+1​ 。特别的，当 v0=vkv_0 = v_kv0​=vk​ 时，称这个路径为闭的（close）；当路径中的顶点互不相同，得到 GGG 的一条路。 连通图 在无向图GGG中，若从顶点viv_ivi​到顶点vjv_jvj​有路径（当然从vjv_jvj​到viv_ivi​也一定有路径），则称viv_ivi​和vjv_jvj​是连通的。 如果G是有向图，那么连接viv_ivi​和vjv_jvj​的路径中所有的边都必须同向。如果图中任意两点都是连通的，那么图被称作连通图。 连通分量 无向图G的一个极大连通子图称为G的一个连通分量（或连通分支）。连通图只有一个连通分量，即其自身；非连通的无向图有多个连通分量。 有向图G= (V,E)中，若对于V中任意两个不同的顶点 x和y，都存在从x到y以及从y到x的路径，则称G是强连通图（Strongly Connected Graph）。相应地有强连通分量的概念。强连通图只有一个强连通分量，即是其自身；非强连通的有向图有多个强连通分量。 二部图 二分图的顶点可以分成两个互斥的独立集U和 V的图，使得所有边都是连结一个 U 中的点和一个 V 中的点。顶点集 U、V 被称为是图的两个部分。等价的，二分图可以被定义成图中所有的环都有偶数个顶点。 许多社会现象或状态的结构，都呈现出二部图的形式 是否有长度为奇数的圈，是判断一个图是否是二部图的充分必要条件。 长度优先搜索（遍历），是考察一个图是否存在长度为奇数的圈的有效方法。 从任何节点开始，在广度优先搜索（遍历）过程中，一旦发现同一层节点之间有边，则图中一定存在长度为奇数的圈，则该图不是二部图。 三元闭包 不仅考虑一个时刻（“快照”）上的状态 还要研究随时间发生的变化（内部原因 vs 外部原因） 社会网络眼花的基本结构性原因（Anatole Rapoport, 1953） 三元闭包(triadic closure) 在一个社交圈内，若两个人有一个共同的朋友，则这两人在未来成为朋友的可能性会提高。 机会（opportunity） 信任（trust） 动机（incentive） 林南 一个特定的网络可以自然地形成 也可以有对一个特定的共同关注的焦点或关注一种资源利益的社会性建构 聚集系数 刻画某个节点的重要性 结构洞 聚集系数，就是在三元闭包中，对一个节点属性的测度，表示“凝聚力”的大小 节点A的聚集系数 = 与A相邻的任意两个朋友之间也是朋友的概率 = 与A相邻的朋友对的个数/总数 在上图a中，节点A的聚集系数1/61/61/6 （因为与A相邻的6个节点对B-C、B-D、B-E、C-D、C-E 和 D-E 中，仅有一个边 C-D ）。 三元闭包的大数据验证 电子邮件网络~~社会网络 可能性：共同朋友 -&gt; 成为朋友的概率 数据验证要求： 网络规模足够大 数据跨度时间足够长 关键： 将社会科学原理的定性描述，转化为便于定量分析的表述，形成数据指标（与共同朋友书对应的概率）。 选择合适的数据，以及从原始数据中提炼出指标数据的方法。 强关系与弱关系 Granovetter(1973)提出了刻画边的属性的一种测度：强 – 弱。 被动参与三元闭包原理实际上暗含了一个随时间推移的可能。 有的人会被动加入某些网络 Huberman et al. (2009) 对Twitter的研究表明，即使所有朋友的总数超过500，实际联系的总数也在10-20人之间；被动联系人的数量也不超过50人。 嵌入性（Embedness） Karl Polanyi (1944) 《大转变》 行动嵌入制度。 Granovetter (1985) 在与经济学家的论战中，提出了经济行为与社会结构之间的关系问题，拓展了嵌入性概念，指出，经济行为是嵌入在社会结构之中的，是社会行为的一种。 网络分析，恰恰是Granovetter从他老师Harrison White (1967) 那里得到的衣钵。 嵌入性：边的属性 嵌入性 = 一条边两端共同的邻里数 看 A - B 边，有共同的邻里 E 和 F，则 A-B 边的嵌入性为 2 嵌入性越强的边，相互之间的信任就越强；嵌入性越强的边，社会资源也就越多 嵌入性与社会资本是两个不同分析框架的概念。 结构洞（结构位置整体） 一个节点，移除该节点就会使网络变成多个连通分量的节点 节点B，移除它，就会变成3个连通分量 结构洞意义 了解三方面的信息 处于捷径的一端，对其 “长处” 有放大影响 对于其相邻的节点甚至具有“权力” 冗余（凝聚力冗余和结构等位冗余）越小的结构洞，社会资本就越多（Burt的结构洞） 强三元闭包 桥(Bridge)：如果一个图中，已知A和B相连，若去掉连接A和B的边导致A和B分属不同的连通分量，则该边称为桥。桥为A、B间唯一路径。 捷径(Local bridge)：若边A-B的端点A和B没有共同朋友，则称边A-B为捷径；删除A-B边将把A-B距离增加至2以上。 强联系：对应朋友(Friend)关系。弱联系：对应熟人(Acquaintance)关系；通过捷径找到工作；亲密团体内信息多数自己已经知道。 两人关系的强度与是否有共同朋友直接相关，捷径意味着没有共同朋友，强度为弱，共同朋友数越多，关系的强度越高。 强三元闭包原理：如果 A 和 B、C之间的关系分别为强关系；则 B 和 C 之间形成边的可能性应该很高。 若A有两个强关系邻居B和C，但B和C之间没有任何关系（s或w），则称节点A违背了强三元闭包远离 如果节点A没有违背强三元闭包原理，则称节点A符合强三元闭包原理 断言：若节点A符合强三元闭包，且至少有两个强关系邻居，则与A相连的任何捷径必定意味着是弱关系。 强三元闭包原理的精神： 没有共同朋友 -&gt; 捷径 -&gt; 弱关系 定量化表述：共同朋友越多，关系强度越 也就是社交网络中，我们预计看到人们关系的强度与共同朋友数正相关","link":"/2020/03/02/Social%20computing%201/"},{"title":"Social computing 2 —— 社会选择与社会影响","text":"同质性 同质性是古老议题： 柏拉图 相似性带来友谊 亚里士多德 人们喜欢与自己相似的人 俗语 夫妻相 Lazarsfeld 和 Merton（在 Simmel的基础上） Berger, et al. 1954. Freedom adn Control in Modern Society. 社会控制、群体与个体 国家与社会 Lazarsfeld and Merton （1954） 区分了 身份同质性：相同身份的人彼此相互联系 → 社会性机制 价值同质性：相同价值观的人会彼此相互联系 → 个体性机制 区分 同质性 Homophily 与同构性 Homogeny Miller McPherson, et al （2001） 用了 birds of a feather 作为篇名，提出同质性的机制 生态过程：场所的影响，同一个机构、社区，共同参加活动 关系过程：交叉关系的影响，一个人在不同的场所 网络过程：随时间的变化而变化的动态 James Moody (2001) 高中生之间的关系：年级、种族 社会交往 每个人的特质（2种） 固有特质：性别、种族、母语等，自然属性 可变特质：居住区、专长、偏好等，建构属性 同质性是社会网络结构形成的基本外部原因 血缘、地缘、业缘、趣缘等 社会学的一个基本问题 是因为“羽毛相似”才交往（selection）呢 还是因为“同林”后才变得“羽毛相似”（social incluence）呢 社交网络中同质性的测量 社交网络中的同质性现象 朋友~~相似 ”相似“的含义可因考虑的问题不同而不同 → 固定特征、可变特征 如何定量评估一个社交网络中同质性现象的程度？ 给定社交网（只考虑两种不同的特征：红，白） 我们能够得到的信息 节点数（n），边数（e） 不同颜色节点的占比：p，q=1-p 两端节点相同的边数（s） 计算： 节点数 n = 9 边数 e = 18 红色节点数占比 p = 13\\frac{1}{3}31​ 白色节点数占比 q = 23\\frac{2}{3}32​ 两端节点相同的边数 s = 13 se&gt;p2+q2\\frac{s}{e} &gt; p^2+q^2es​&gt;p2+q2 ? → se\\frac{s}{e}es​ = 1318\\frac{13}{18}1813​ p2+q2=132+232=1018p^2+q^2 = {\\frac{1}{3}}^2 + {\\frac{2}{3}}^2 = \\frac{10}{18}p2+q2=31​2+32​2=1810​ ∵ se&gt;p2+q2\\frac{s}{e} &gt; p^2+q^2es​&gt;p2+q2 ∴ 同质性现象在这个社交网络中有所表现 认识：两边节点的边越多（占比越高），同质性越明显se\\frac{s}{e}es​ 用“随机情况”作为基准：给定不同颜色的节点占比（红p和白q），随机情况下，一个节点是红色节点的概率为p，白色的概率就是q，那么任何一条边的两节点颜色相同的概率就是p2+q2p^2+q^2p2+q2，也就是两端节点相同边的占比。 物以类聚人以群分 经验观察 俗语 物以类聚，人以群分 亚里士多德 人们喜欢与自己相似的人 理论 Lazarsfeld 与 Merton (1954) 区分了选择机制 身份同质性：相同身份的人彼此相互联系 价值同质性：相同价值观得人会彼此相互联系 即人们通过自然属性或社会属性的相似性、或价值观的相似性进行选择 理解 为什么身份与价值观会影响社会网络同质性的动态 作为能动者的行动者（Giddens,1984; 1991），个体具有“加入”的主动性和自主性 （自然行为） Examples 你的朋友带来了一位对你而言是陌生人但却是你朋友的朋友来见你 同样，还具有退出的主动性和自主性 Examples 教会吸收新会员，学生社团吸收新成员 网络的同质性，实际上是一个动态过程，即使是主动选择的 从属网络 社会交往 社会网络的建构，无论是加入，还是退出，都可能是一个主动的过程 尽管被动参与（参见嵌入性）也是一种机制 形成网络同质性的机制之一，是个体（节点）的主动选择 近朱者赤近墨者黑 经验观察 传统故事 孟母三迁 俗语 近朱者赤，近墨者黑 婚姻 先结婚，后恋爱 理论 Miller McPherson, et al (2001) 同质性的机制 生态过程：场所的影响，同一个机构、社区，共同参加活动 关系过程：交叉关系的影响，一个人在不同的场所 网络过程：随时间的变化而变化的动态 强调生态性的重要性 由场所带来的影响，实际是同质性形成的另一个重要机制 从属关系与社会关系的相互总用（随时间发生的变化） 社会归属网：描述从属关系与社会关系 在现实社会中，选择与影响似乎很难明确区分，实际是交替甚至同时发生的现象，同质性是两种共同机制的结果 选择 → 社团闭包 影响 → 会员闭包 社会归属网：三类闭包 社团闭包的验证 社团闭包 由于参与一件事情，两个原本没联系的人之间，建立了联系 共同参与的事情越多，建立联系的可能性越高 会员闭包的验证 会员闭包 由于朋友参与某件事情中，原本不在这件事情的另一个人也加入了这件事 参与某件事的朋友越多，其被影响而参与的可能性就越大 社会影响与社会交往 个体的兴趣与能力，或许不限于既有，可能会被诱发 体育特长，自然的、本性的 拓展是可以选择的，更多或是受到影响的 Iphone一族；三星一族 形同同质性网络的机制之一，是个体之间的相互影响 ”朋友~~相似“现象溯源（大数据分析） 朋友间相似的原因？ 当两个关系不过的人在某些特质上相似 相似 → 朋友？ 朋友 → 相似？ 需要数据集 反应随时间变化的大规模社会归属网 大规模：人多，社交聚点多 随时间变化：人与人之间，人和人的社交聚点之间 wikipedia数据集 两人相似性的测量 相似性=两人都编辑过的文章数总共编辑过的文章数相似性 = \\frac{两人都编辑过的文章数}{总共编辑过的文章数}相似性=总共编辑过的文章数两人都编辑过的文章数​ 相似性、选择与社会影响 小结 利用“社会归属网”大数据剖析同质性现象的原因 从问题，到模型（社会归属网），再到数据（Wikipedia），最后到映射（数据与问题要素的关系） 谢林模型及其意义 从一个现象开始 芝加哥，黑人在居住区的比例变化图 同质性动态 现象 越来越多的黑人在某个区域聚集 理解 自然属性相同，选择相同 相互认识，相互影响，进而趋同 谢林模型示意 Schelling (1972, 1978) 隔离的动态模型（1972）：隔离不是个人刻意选择的后果 微观动机与宏观行为（1978，2005） 谢林模型的社会意义 以居住隔离为例，谢林模型模拟了同质性的动态变化。 如果同质性是一个自然现象，则促进或阻止不同社会情景下的同质性，将会对社会发展产生重要影响。","link":"/2020/03/05/Social%20computing%202/"},{"title":"Social Computing 3 —— 小世界实验及其惊奇","text":"小世界问题 The Small-World Program S. Milgram (1967) 实验 现象：俗语 &quot;My it&apos;s a small world.&quot; 问题：两个互不相识得人，如果想认识，中间需要经过几个人 意义： a certain mathematical structure in society 假设 由于每个人都有熟人，熟人之间没有芥蒂，可以交往。故，不曾有连接的两个人之间，如果要建立连接，中间人的数量应该不多。 每个人的确都有熟人，不过，不同类型或阶层熟人之间，不会有交往。故，不曾有连接的两个人之间，不可能建立连接 设计 选择一个随机起点，观察需要经过多少个中间人，能够到达目标点 规则 参与这只能将信件转发给能够直呼其名的熟人，并请他继续转发；如果一个参与者不认识目标收信人，则他不能直接将信寄给他； 参与者需力争让信件尽早达到目的地 第一次：从Kansas的Wichita到哈佛大学神学院某学生的妻子 第二次：从Nebraska的Omaha到Boston的Shanron的股票经纪人Jeffrey Travers 结果 平均中间人数：5 小世界现象 小世界问题 在Milgram的研究之前，人们感觉世界很小，却没有证据 MIT的师生试图证明这一点，不过没有结果 来自Harvard的Milgram用信件进行传递，得到了一个平均数 小世界现象 —— Milgram的研究证明 世界是小的（六度分隔）；社会网络中包含丰富的短路径 “自动寻找”短路径；“有意识的转发”能“自动地“找到这些短路径 启发 为什么社会网络具有这样的性质？它们源于社会网络的哪些基本原理？ 能否依据社会网络的某些原理，构建出反映这种性质的网络模型？ 总结 一项试图证明“世界是小的”简单研究，提示了或许在人际关系之间，的确存在着某种数学结构 小世界现象的普遍性 后续研究 不少重复研究，包括Milgram（1970）自己 扩展 运用书信所做的研究具有重复性，电子邮件呢？ Dodds, Muhamad and Watts (2003) 60,000个电子邮件用户 通过给熟人转发电子邮件的方式，将邮件送达13个国家的18位收件人 发现 通过认识的人，不一定有多熟悉 中间路径：5-7步 网页之间的“社交” 全球互联网超过几百亿的网页，比人口总数多 问题 —— 网页之间，又怎样的关系，也有“小世界”现象吗？ Albert, Jeong, Barabási(1999); Barabási(2013) ——没有关系的两个网页之间的直径为18.59次点击 总结 通过熟人送文件（书信）在不断地检验小世界现象的存在 即使加上了“种族”的因素，小世界现象依然存在 在电子邮件时代，通过熟人转发电子邮件，依然有小世界 即使在网页之间的“社交”，也有短路径 关于小世界的 Watts-Strogatz 模型 人类社会的小世界现象 社会网络中两节点间包含丰富的短路径 —— 任意两节点间存在短路径的概率很高 短视搜索能够有效地找到这些短路径 —— 短视搜索：在达到目标节点过程中，每一步只能看到邻居节点 对于“十分稀疏”的社会网络来说，这并不是必然 从现象到问题 问题 为什么社会网络具有这样的性质？它们源于社会网络的那些性质？ 可以证明，完全随机的网络没有这样的性质 换句话说，能否依据社会网络的某些基本原理来证明这种性质的必然性呢？ 形成社会网络的两种力量 同质性 共同朋友，邻里关系，同学，同事，共同兴趣 对应社会网络中大量的“三角形”（圈子） 弱联系 偶然的原因，认识的“远程”朋友 对其所在的圈子并不一定熟悉 能否找到一种形式化网络，既能够体现这两种力量的作用，也便于我们分析其中是否具有小世界现象？ Watts-Strogatz 模型 定义一种图（网络），体现上述因素 有许多“三角形”和少数随机的“远程边” 每两点之间有一个“网格距离” 大量节点拍不成均匀的网格状 连接近邻：确定性，连接远程：随机性 模型中节点间有两个距离的概念：网格距离和网络距离 体现了同质连接和弱关系连接的概念，于是可以看成是现实社会网络的一个合理近似 可以证明：在这样的网络中，任意两节点之间存在短路径的概率很高 也可以证明，Watts-Strogatz模型不能很好滴体现第二个要求 短视搜索路径太长，尽管短路径存在 总结 对于重要的社会现象，如果可以使用一个数学模型来解释，尽管这个模型概括不了现象的所有细节，也是值得追求的 Watts-Strogatz模型，抽象地表达了社会网络成因的基本特征，从理论上说明了小世界现象（一个方面）的必然性 关于小世界的Watts-Strogatz-Kleinberg 模型 Watts-Strogatz模型的意义与局限性 证明了模型网络中任意两个节点之间存在短路径的概率很高，即“小世界” 但不能解释Milgram等人实验反映出的小世界现象的另一个层面：在短视搜索情况下能找到短路径 在模型上执行短视搜索，常常导致较长路径 短视搜索（分散搜索） 有目标；每一步只有局部知识；与目标进行对比 相对于我们已经熟悉的“广度优先索索”（无目标），这是一种有目标的基于局部信息的搜索，具有如下特点： 每个节点都有一个特征，任何两个节点间的特征可以谈差别（距离） → 不同于图论中定义的距离 每个节点都知道目标节点的特征，也知道自己和自己邻居节点的特征 搜索过程中可以看做是信息传递的过程，节点将信息传递给离目标节点距离较近（差别较小）的邻居节点 示例 节点：0, 1, ..., 9, A, ..., F 特征距离（差别）：由环上相对位置定义，例如节点0和A的距离为6 从0开始，以A为目标的短视搜索：0-C-B-A 而不是 0-F-A 短视搜索没走“最短路径”！ 一种一般的认识论方法 经常，在事物的宏观格局中存在某种性质，但若缺乏宏观视野，仅凭基于微观视野的追求，不一定能够发现那种特质 但如果事物的结构存在某种特征，使我们能够证明，基于微观视野的追求，就能揭示宏观性质，则是十分美妙的事情。 通过局部，了解全局；通过微观，理解宏观 在小世界问题上我们面对： 在人类社会网络上的大量实验结果表明：短视搜索是有效的，这说明现实社会网络结构支持这种做法 在WS社会网络模型上的理论分析表明，短视搜索效果不好，这说明该模型没能抓住现实网络的某个重要特点 因此，我们需要一种社会网络模型 既反映节点对之间短路径的存在性，也支持这种信件转发方式下短路径的可实现性 网络中需要什么样的结构特征来体现这样的要求呢？ 两个节点无论相距多远，都要有机会很快接近 两个节点的距离越近，存在直接连接的机会越大 Watts-Strogatz-Kleinberg模型 在WS模型基础上，让两个节点之间存在随机边的概率与它们网格距离的某个幂次（q）成反比 q值较小，随机边倾向于较远；q值较大，随机边倾向于较近 Watts-Strogatz模型对应于 q=0q = 0q=0 的情况 改模型的最佳工作参数（q） 理论结果：当 q=2q=2q=2 时 ，分散搜索达到最佳效果 仿真实验：由几亿个节点组成的网络中，考察不同的 q 值在分散搜索中的效果 总结 发现WS模型不能反映现实社会网络的一个重要特征，促成了WSK模型 WSK模型通过适当控制WS模型中的随机性，与试验结果更加吻合 改模型出现了一个优化参数（q），当取特定值时效果最好，这个参数在现实社会网络中如何体现的呢？ WSK模型中优化参数的大数据验证 Milgram的实验表明，现实社会网络中，分散搜索的路径很短。于是很值得好奇：难道人们成为朋友的概率真的岁空间距离递减，并且递减强度幂次 q 真的等于 2 吗？ 利用在线社会网络进行验证 真实大规模在线社会网络是否体现了这个（WSK）网络模型的优化性质？ 两人成为朋友的概率与其空间距离的平方成反比 如果是，则说明随即形成的社会网络可能具有某种本质参数！ 但，在线社会网络的节点如何谈空间距离？ 来自LiveJournal的实验数据 50万用户，含邮政编码 分布不均匀，不符合模型的假设，需要做一些适配性工作 社会网络中结合地理距离的节点相对排名 可以看成是节点在地理距离上均匀分布时区域范围概念的一种推广，“排名”与“距离”有对应关系 这就是我们能一般性地处理节点在地理上分布不均匀的问题 要验证的是： 在均匀地理分布情形，一个节点在任意距离上的朋友数量在同等距离节点总数中的占比随距离平方递减 1d2\\frac{1}{d^2}d21​ 此时等价于看 一个节点在任一排名上的朋友（即有连接）数量在同等排名节点总数的占比随排名递减 1r\\frac{1}{r}r1​ 这意味着，大量微观社交关系的建立总体上呈现出一种最优化特征，或者说大量人群的随机社会活动相当于一台计算机，完成了一种优化计算（实现了最优参数）—— 这可以看成是社会计算的一个实例，也是体现社会系统中微观与宏观关系的实例。 总结 前面的内容，讨论了人们围绕小世界现象所展开的一系列研究思路 看到了“实验 → 理论 → 完善 → 实验”研究范式的体现 （小世界）现象 → 抽象模型（解释现象） → 完善模型 （更好地解释） → 数据验证（得到对现实更深入的认识） 也看到了大数据分析在推进这类研究中的作用 核心—外围结构：一种社会网络观 核心-边缘结构模型 Borgatti 和 Everett (1999) 观察到，在社会网络中 地位较高的人，被连接在一个密集连接的核心 地位较低的人，都分散在网络外围 核心 - 边缘结构 不仅是在理论上 现实社会中，普遍存在 理论与现实 理论上 处在网络结构中的节点，不同的节点如果有相同的聚集系数，其被连接到的概率是一样的 现实中 Milgram(1967)的第一次试验就已经暗示：寻找地位较低得人（神学院学生的妻子）会更加困难 人们观察到，“媒体寻人”较之个体寻人有更高的成功率 回想“结构洞”，处于结构洞位置上的人，其被找到的概率，远远大于一般节点上的人 社会意义 如果处于更高的社会地位，且在结构洞的位置上呢？故 网络结构本身是重要的，尤其在可计算性上 同样重要的是，网络结构的社会属性 具有相同网络结构，却有着不同的社会属性的网络，在显示社会中，具有布偶听的“可连通性”（社会含义） 社会地位较高的人，具有更多的“关系资源”，更好的连通性 总结 网络结构会因为节点上的人的社会属性不同，而有不同 社会地位较高的人，倾向于有更多的、更广的关系（连接） 即，社会属性是影响网络结构及其连通性的重要因素","link":"/2020/03/06/Social%20computing%203/"},{"title":"Social computing 5 —— 博弈论","text":"博弈论的基本概念 博弈（game） 博弈三要素： 参与人（player，玩家） 策略集（strategy，战略） 回报（payoff，收益、支付） 次序（order） 均衡（equilibrium） 每个参与人都有一个策略集； 策略组：每个参与人出一个策略构成策略组合 对应每个策略组，每个参与人都有一个回报 田忌赛马 参与人：齐威王、田忌 策略集 上中下 上下中 中下上 中上下 下上中 下中下 回报 对于策略组（1，1），田忌（-3） 对于策略组（5，1），田忌（+1） …… 博弈不总是讲输赢 商场走失问题：两友人同逛一个大商场，走散了。已知商场有南北两个门，也知道朋友会在某个门等候，你会去哪个门？ —— 只有协调，才能共赢 收益矩阵（表达博弈的一种直观方式） 博弈论的关切（不同于博弈参与人的关切） 在”理性人“等基本假设下，博弈（作为一个整体）的结果、走向、发展趋势、哪些策略组（合） 会被人们采用。 博弈推理的假定（assumption） 自己的回报是每个参与人关心的唯一因素 参与人都是 “理性人” ，即只要可能，总是要选择有更好回报的策略 每个参与人都对博弈结构完全了解 个体理性与集体理性 个体理性 个人理性是指个人分析问题，决定自己行为取向时所表现的理性。 集体非理性 集体理性是指集体在决定和从事集体行动所表现出来的理性，而集体非理性则相反。 无论是个人理性、集体理性还是集体非理性，他们强调的是在选择和策略过程中表现的一种思维思考活动。 一个博弈的解，是“稳定的策略组”，要求是其中任何参与人不可能通过单方面改变策略而获得更好的回报。 ”稳定的“ → 在博弈推理假设下不可能再变化 不是所有的博弈都有解 这里解的概念，实际上就是博弈均衡的概念。 策略L 策略R 策略U 90,90 86,92 策略D 92,86 88,88 严格占优策略：对一个参与人来说，若存在一个策略，无论另一个参与人选择何种策略，该策略都是严格最佳的选择，则这个策略就被称为是前者的严格占优策略。 按照博弈推理假设，参与人将选择严格占优策略。 严格与不严格的区别 L R U 3，3 4，3 D 2，0 3，4 横向为参与人1，纵向为参与人2 U是参与人1的严格占优策略；R是参与人2的占优策略，但不是严格的 L是U的最佳应对，但不是最严格的；R是D的严格最佳应对 简单博弈的行为推理 如果两个人都有严格占优策略，可以预计他们均会采用严格占优策略。 如果只有一个人有严格占优策略，则这个人会采取严格占优策略，而另一方会采取此策略的最佳应对（一定会有）。 占优策略 → 占优策略 ； 占优策略 → 最佳应对 互为最佳应对策略组 → 纳什均衡 具有多个纳什均衡的博弈 如果两个人均没有严格占优策略呢？ 如何讨论博弈的走向？ A B C A 4,4 0,2 0,2 B 0,0 1,1 0,2 C 0,0 0,2 1,1 三客户博弈的解，横向为公司1，纵向为公司2 策略组（A，A）中的两个策略为最佳应对 纳什均衡：互为最佳应对的策略组。 协调博弈 北门 南门 北门 1，1 0，0 南门 0，0 1，1 横向为你，纵向为你的拍档。 有两个纳什均衡（北门，北门）与（南门，南门） 如何预测协调博弈中参与人的行为？ 引入外部条件 鹰鸽博弈的推理 两个均衡，不能推断出哪个均衡会出现 一般来说，纳什均衡的概念能够有助于缩小预测的范围，但它并不一定能够给出唯一的预测 如果不存在纳什均衡，怎么办？ 零和博弈（zero sum game） → 猜测他人的策略，不让他人预测你的策略 混合策略的引入 引入随机性，考虑参与人将以一定的概率在不同策略间进行选择，一个概率对应一个“策略”（称为混合策略）。此时，选择策略就是选择策略，而博弈矩阵中给出的选项称为寸策略。 一般地，混合策略是一个概率分布，双策略情形等价为一个概率。 通常地，在有两个纯策略H和T的情形，我们说： 你的策略概率是ppp，是指你以概率ppp执行 H； 以概率1−p1-p1−p执行T。 他的策略概率是qqq，是指他以概率qqq执行H；以概率1−q1-q1−q执行T。 针对混合策略的博弈，三要素齐全了吗？ 参与人 √ 策略（概率） √ 回报 ？ 此时的策略是两种（纯）策略上选择的概率，每一组纯策略是对应有固有收益的。因而，从概率意义出发，此时的收益应该体现一种在两种纯策略上的“平均”（期望）。 但是，在研究一个混合策略博弈的时候，我们一般并不关心在每个策略下的具体回报情况，而是关心是否能够达到均衡？在什么混合策略组下达到均衡？哪两个概率是互为最佳应对？ 最佳应对：改变策略后，不会得到更好的回报。 博弈均衡有两种：纯策略均衡、混合策略均衡； 任何博弈都存在均衡： 可能有一个，也可能有多个 可能是某一个，也可能两种都有 社会最优 均衡是博弈的解（走向、结果），参与人都实现个体最优，但不一定是社会最优。 帕累托最优（Pareto Optimality） 帕累托最优是指资源分配的一种理想状态。 假定固有的一群人和可分配的资源，从一种分配状态到另一种状态的变化中，再没有使任何人境况变坏的前提下，使得至少一个人变得更好。 帕累托最优的状态就是不可能再有更多的帕累托改进的余地；换句话说，帕累托改进是达到帕累托最优的路径和方法。帕累托最优是公平与效率的“理想王国”。 一组策略选择是社会福利最大化（或社会最优），若它使参与者的回报之和最大。 社会最优和纳什均衡有可能一致。 从社会应用的意义讲，均衡与社会最优一致的系统是理想系统。 相关概念 纳什均衡（Nash Equilibrium） 在一策略组合中，所有的参与者面临这样的情况：当其他人不改变策略时，他此时的策略师最好的。也就是说，此时如果他改变策略他的回报（payoff）将会降低。 在纳什均衡点上，每一个理性的参与者都不会有单独改变策略的冲动。 纳什的奠基性贡献：证明了具有有限参与者和有限纯策略集的博弈一定存在纳什均衡（包含混合策略均衡）。 零和博弈（Zero-sum Game） 零和博弈是一种非合作博弈，指的是参与博弈的各方，在严格竞争下，一方的收益必然意味着另一方的损失，博弈各方的收益和损失之和永远为“零”。双方不存在合作的可能。 零和博弈的结果是一方吃掉一方，一方的所得正是另一方的所失，整个社会的利益不会因此增加一分。 非零和博弈（Non-zero-sum Game） 非零和博弈是一种非合作下的博弈，博弈中各方的收益或损失的总和不是零值，它区别于零和博弈。在经济学研究中很有用。 在非零和博弈中，对局各方不是完全对立的，一个局中人所得并不一定意味着其他局中人要遭到同样数量的损失。也就是说，博弈参与者之间不存在“你之得即我之失”这样一种简单的关系。 参与者之间可能存在着某种共同的利益，博弈参与者可能实现“双赢”或者“多赢”。 囚徒困境（Prisoner&apos;s dilemma） 两个嫌疑犯（A和B）作案后被警察抓住，隔离审讯。警方的政策是“坦白从宽，抗拒从严”，如果两个人都坦白则各判8年；如果一个人坦白，另外一个人不坦白，则坦白的放出去，不坦白的判刑十年；如果都不坦白，则因为证据不足各判1年。 囚徒困境最早由美国普林斯顿大学数学家阿尔伯特·塔克（Albnert Tucker）在1950年提出来，他当时编了一个故事向斯坦福大学的一群心理学家们解释什么是博弈论，这个故事后来成为博弈论中最著名的案例。 → 此时，都坦白是二者的严格最优策略。","link":"/2020/04/02/Social%20computing%205/"},{"title":"Social computing 6 —— 网络流量的博弈","text":"网络流量的博弈 网络结构上的博弈 公路交通网 网络中的博弈 假设有4000辆车，都要从A走到B 参与人： 4000位司机 策略选择：ACB 或 ADB 回报：行驶时间（越小越好），显然也取决于他人的策略 &quot;均衡&quot; = 没人通过改变选择可以得到更好的回报 均衡：上下路各有2000辆车；对于每辆车而言，对应回报为65。 此时，若某人要改变，则他的行驶时间为 2001/100+45&gt;652001 / 100 + 45 &gt; 652001/100+45&gt;65，因此无人改变 假设，C→D之间修一条快速路，则 若大家都走：A → C →D→B，则每个人的行驶时间为4000/100+0+4000/100=804000/100+0+4000/100=804000/100+0+4000/100=80 注意，在没修这条路之前，均衡中每个人行驶时间为65 如果某人打算改变为A→D→B，则他的行驶时间将变为45+4000/100&gt;8045+4000/100&gt;8045+4000/100&gt;80，于是他不会改变！ → 布雷斯悖论 为什么大家不能像从前那样？ 你会很合理地想走A→C→D→B，也就是说，从前那样的交通模式是不均衡的。 你会这么想，其他人呢？ 小结 通过一种简单的交通网络模型，我们看到“在网络上的博弈”的一种范式，特别是结构对均衡的影响。 我们看到了“布雷斯悖论”的出现，它其实可以看成是我们现实生活中有时看到“投入资源反而使情况更糟糕”情形的一种简单化、但有效的解释。 这个例子也告诉我们，在现实生活中，参与一个博弈，可能是无形中的。 布雷斯悖论的一般性 布雷斯悖论（Braess’s paradox）指的是一个交通网络上增加一条路反而是网络上的旅行时间增加。 例子： 高速公路免费带来的影响 2012年中秋开始，政府颁布一项惠民政策，即： 在法定节假日，高速公路免费通行。 每年中国高速公路公司将因此减收200亿人民币，与此同时免费政策也引发各方争议： 免费带动了消费额，远远大于高速公路公司的减收。 免费也带来了高速公路的拥堵，旅游景点的人流饱和等。 高速公路免费带来影响的理论化 与布雷斯悖论不同的地方在于，除了结构与流量关系之外，这个例子涉及多个行动者： 高速公路公司、车主及其家庭、政府 简化模型 免费政策 = 多修了一条公路 通行时间 = 交通总成本，包括时间和费用 布雷斯悖论的一般化 如此，我们是不是看到了另一种形态的布雷斯悖论 虽然也是交通网络，却是另一种形态 探讨 通行时间 - 流量 - 成本 - 社会成本 布雷斯悖论的含义是，通过网络结构的变动，意在改善交通行动，结果是导致了更加糟糕的交通。 中国高速公路免费所产生的效应，看起来类似 那么我们是否可以把布雷斯悖论做进一步抽象？譬如说 “好心办坏事”，意在增加社会福利的行动，反而增加了社会成本 例如： 意在改善儿童教育机会的制度变动，其结果是对学校需求的更加不平衡，有些学校无人问津，有些学校则挤破脑袋 同样，改善就医便利程度和降低个人就医负担的制度变动，其结果不仅是就医总费用急剧增加，对医院的需求更加不平衡，高等级医院挤破脑袋，社区医院门可罗雀。 小结 布雷斯悖论是社会政策、公共服务中可以意会到的现象 意会与科学论证，是两回事，对布雷斯悖论的推广，应该还是一个可探索的领域。 拍卖的意义及其形式 拍卖的普遍性 拍卖（auction）是很典型的节点之间的互动，例 佳士得、苏富比拍卖艺术品 政府拍卖土地、车牌 毕业摆摊，买旧物 竞标（bidding）也是一种拍卖 卖家将合同机会进行拍卖 拍卖的意义 拍卖是普遍存在的经济互动形态 模式简单，互动却复杂 也是博弈论应用的典型场景 参与者：参加拍卖的人，买卖双方，相当于两方博弈 策略：出价 收益：对物品的估值（支付价格）或为零，即不成交；对卖家而言，就是其得到的支付价格，或为零。 均衡：即在该状态下所有参与者的策略互为最佳应对，任何个人都没有理性的冬季来改变自己的策略，在拍卖中如何体现？ 拍卖的形式 在拍卖中，均衡是拍卖规则下的均衡，因此拍卖规则或拍卖形式，对均衡的达成有直接影响。 最简单的，单品拍卖。 英式拍卖 （古董艺术品的拍卖） 也称为“出价逐升式拍卖”，是目前最流行的网上拍卖方式。拍卖中，竞买人出价由低开始，此后出价一个比前一个要高，直到没有更高的出价为止，出价最高即最后一个竞买人将以其所出的价格获得该商品。 既然获胜的竞买人的出价只需比前一个最高价高一点，那么每个竞买人都不愿马上按照其预告价出价。当然，竞买人也要冒风险，他可能会被令人兴奋的竞价过程吸引，出价超出了预估价，这种心理现象被称为赢者诅咒（Winner&apos;s Curse）。 荷兰式拍卖（农产品） 是英式拍卖的逆行，也称为“出价逐降式拍卖”。它是先由拍卖人给出一个潜在的最高价，然后价格不断下降，直到有人接受价格。该方式的缺点是拍卖速度太快，而且需求所有竞买人在某一时候竞买。 密封拍卖（Sealed Auction） （适合招标、互联网广告） 是指竞买人通过加密的E-mail将出价发送给拍卖人，再由拍卖人统一开标后，比较各方递价，最后确定中标人。 密封拍卖可分为一级密封拍卖和二级密封拍卖。一级密封拍卖也称为密封递价最高价拍卖，即在密封递价过程中，出价最高的竞买人中标。如果拍卖的是多件相同物品，出价低于前一个的竞买人购得剩余的拍卖品。二级密封拍卖也称为密封递价次高价拍卖，其递价过程与一及密封拍卖类似，只是出价最高的竞买人是按照出价第二高的竞买人所出的价格都按其预告价出价，降低了竞买人串通的可能性，获胜者不必按照最高价付款，从而使所有的竞买人都想以比其一级密封拍卖中高一些的价格出价。威廉.维克瑞（William Vickrey）因对此拍卖的研究而荣获1996年诺贝尔经济学奖，因此，二级密封拍卖也称为维氏拍卖。 双重拍卖(double auction) Open-outcry double auctions（开放出价双重拍卖） Sealed-bid double auctions（密封递价双重拍卖） 次价支付 假设有一件物品 不同人对其价值有不同的看法，v1, v2, v3, ... , vk 每个人都有一个竞价：b1, b2, b3, ... , bk 则 vi−biv_i - b_ivi​−bi​ 就是 i 可能得到的收益 次价拍卖规则 出价最高者得到购买权，但只需支付（b中的）次高价 出价策略 如果大家都按照自己真实的估值出价 则没有人能通过改变，获得更大的回报；这种情况下，大家互为最佳应对，均衡；尽管改变出价可能得到同样的回报 如果某个人不按照自己真实的估值出价 其他人按照估值出价，则他的回报要么没变化，要么变少，总之不可能获得更好的回报 因此“次价出价”是鼓励买家按照自己的真实估值出价 真的吗？ bi&gt;vib_i &gt; v_ibi​&gt;vi​ 提高报价，只是当超越其他人报价才有差别，但在这种情况下，就要支付比估值多的钱 —— 亏了 bi=vib_i = v_ ibi​=vi​ 真实报价 bi&lt;vib_i &lt; v_ibi​&lt;vi​ 降低报价。只是当低于其他人的报价才有差别，但这种情况下，就得不到交易权，因此没意义了。 拍卖规则要点 成交规则，谁获得拍品？ 通常是报价最高者或最低者。 支付价格，首价或次价 次价规则的引入，对于竞拍者的出价策略是有影响的。 是否知道他人出价 密封拍卖是不知道的，需要竞价者做出独立判断，且是否竞得，只有一次机会 非密封拍卖，知道他人竞价，且会受到他人出价的影响 小结 日常生活中，拍卖是随时发生的现象，对于我们理解博弈论的应用是一个难得的典型情景。 拍卖的形式多种多样，简单的、复杂的拍卖，从出价方式来看，有增价、降价、密封，三种形式；从支付方式看，有首价、次价两种方式。 拍卖中的博弈与占优策略 密封报价拍卖的两种形式 首价密封拍卖（FPA） 最高报价者得到交易权，支付最高报价。 次价密封拍卖（SPA） 最高报价者得到交易权，支付次高报价。 次价密封拍卖问题 一件物品 估值，不同的人对它的价值有不同的认识（即底价，最多愿意花的钱），v1，v2，... ，vk 每个人提出一个竞拍价， b1 &gt; b2 &gt; ... &gt; bk 次价拍卖规则：出价最高者得购买权，但只需支付（b中）第二高的出价，即 v1−b2v_1-b_2v1​−b2​是出价最高者参与人得到的收益，其他人为0。 什么策略最优？ 博弈论视角（占优策略）：不可能通过改变其他策略得到更大的回报，无论别人出价策略如何。 回报： 估值 - 付出 结论：按照自己的估值出价最优！（非严格占优策略） 论证 假设在一次拍卖活动中，你认为拍品的估值最多为100元，你也考虑出价100元，现在考虑你能否通过不同的出价获得较大的回报 第一，你获得交易权。此时，你有正回报 提高报价也不会改善回报 降低报价，若不低于第二个人的，也不会改善回报，若低于第二个人的，则失去交易权，回报变成0（变少了） 第二，你没有获得交易权（有人出价x &gt; 100），此时，你的回报为0。 降低报价不会改变回报。 提高报价，若不高于第一个人的报价，也不会改善回报。若高于第一个人的，你赢得了交易权，但要支付原来第一个人的报价（高于你的估值），于是回报为负（减少了） 小结 采用次价密封拍卖的规则，拍卖一件物品，对参拍人来说，按照估值报价是占优策略 现实中，参拍人自觉应用这个结论的困难自安于每个人其实很难知道自己对一件物品的“估值”到底是多少 “估值” ≠ “我愿意出的钱数” “估值” = “我绝不接受高于这个钱数” 首次密封拍卖没有这个性质 匹配问题 2012年度诺贝尔经济学奖得主是劳埃德·夏普利和艾文·罗斯，两人研究市场制度下参与者之间如何达成配对的理论和实践问题，其中“GS算法”有重要地位。 学生必须合适的学校匹配，需要移植器官的患者必须与器官捐赠者匹配。这样的匹配如何才能尽可能高效的完成？什么样的方式对哪一方更有利？劳埃德•夏普利采用所谓的“合作博弈”理论去研究和比较不同的匹配方法。“求解”的难点在于确保匹配的结果是稳定的这一突出贡献，也就是说，两个代理人无法找到对方在当前情况下条件优于自己地方。而且，夏普利和他的同事创造了具体的方法即——Gale-Shapley algorithm来确保匹配是稳定的。这些方法也限制了代理人操纵匹配过程的动机。 艾文•罗斯认识到，Shapley值的理论结果可以解释在实践中重要市场的功能。通过一系列的实证研究，罗斯和他的同事证明，稳定是特定的市场机构成功的关键。罗斯后来在系统实验室中的实验都证实这一结论。他还帮助重新设计现有的医院和医生，学校和学生，器官捐献者与患者进行稳定匹配的机制。这些改革都基于Gale-Shapley算法，且考虑到具体情况和道德限制，如排除了侧面支付等问题，使得这一机制更有可操作性。 匹配是人类社会中常见的基本问题之一，会出现在各种不同的背景下。 匹配市场问题框架 卖方，买方，估值矩阵 简单匹配问题 二部图是表达这种供需关系的工具 问：是否存在一种安排（配置）使得每个人都满意？ 二部图中完美匹配：一组边，覆盖了所有的节点，没有节点冲突 这两个图体现的要求能否被满足？ 不能满足 = 存在受限组；S, N(S) 能被满足 = 存在完美匹配 基于估值的匹配问题 人们表达偏好不一定就是”要“与”不要“，对于不同的物品，可以有多样性的估价值判断 同一个物品，不同的人，估值可能不同 同一个人，不同的物品，估值可能不同 如何在”人“和”物品“之间配置（匹配）？ 如何评估一种安排的好坏？ 在经济学中，社会福利 = 参与人收益综合 社会最优：收益综合最大 小结 匹配问题描述的基本框架，参考上面的图 通过简单匹配问题，引入供需关系之间的二部图表达方式 不同供需配置方案的优劣比较指数 —— 社会福利，以及对“社会最优”性质的认识 匹配问题的解 利用收益矩阵计算 偏好卖家图（市场经济原则，涨价） 匹配问题的解 “计划经济”： top-down，从宏观结果到具体安排 市场经济思路 引入价格机制，让需求方选择（博弈），看最后能否达到宏观最优的结果。 清仓价格：每个需求方都能无冲突地得到最大的收益（差价） ？ 清仓价格同时也导致社会福利最大？ 清仓价格 → 最大的 ∑ 估值 ∑ 收益（差价） = ∑估值-∑价格 考虑清仓价格，以及偏好卖家图中的完美匹配对应的配置（M） 每一个收益都是最大 → “∑收益”最大 → “∑估值”最大 小结 以匹配问题为背景，比较“计划经济”与“市场经济”思路 简单模型，体现要点 “市场无形之手”含义与优势的一种解释 参考 # 拍卖形式有哪几种 # 匹配问题 孙立坚:2012年诺奖的理论贡献对政策设计的影响","link":"/2020/04/02/Social%20computing%206/"},{"title":"Social Computing 4 —— 万维网结构、链接分析与网络搜索","text":"一、有向图 有向图是指一个有序(V(D),E(D),Ψ(D))(V(D), E(D), \\Psi(D))(V(D),E(D),Ψ(D))，其中Ψ(D)\\Psi(D)Ψ(D)是关联函数，它使得E(D)E(D)E(D)中的每一个元素（称之为有向边或弧）对应于V(D)V(D)V(D)中的一个有序元素（称为顶点或点）对。 出度与入度 设DDD是一个有向图，DDD中的顶点vvv的入度dD−(v)d_D^-(v)dD−​(v)是指以vvv为头的弧的数目，vvv的出度dD+(v)d_D^+(v)dD+​(v)是指以vvv为尾的弧的数目，vvv的度dD(v)d_D(v)dD​(v)则是出度和入度之和，我们用δ−(D)\\delta^-(D)δ−(D)和Δ−(D)\\Delta^-(D)Δ−(D)和δ+(D)\\delta^+(D)δ+(D)和Δ+(D)\\Delta^+(D)Δ+(D)分别表示DDD中顶点的最小和最大入度、最小和最大出度，并使用δ(D)\\delta(D)δ(D)和Δ(D)\\Delta(D)Δ(D)分别表示DDD中的顶点最小度和最大度，并用v(D)v(D)v(D)，ε(D)\\varepsilon(D)ε(D)来源表示DDD中的顶点数和弧数。 孤立点 VVV中不与EEE中任一条边关联的点成为DDD的孤立点。 简单图 不含平行边的图。 完备图 图中任何两个顶点UUU和uuu之间，恰有两条有向边(u,v)(u, v)(u,v)及(v,u)(v, u)(v,u)，则称该图为有向图DDD的完备图。 基本图 把有向图DDD的每条边出去定向就得到一个相应的无向图GGG，称GGG为DDD的基本图，称DDD为GGG的定向图。 强连通图 给定有向图G=(V,E)G=(V, E)G=(V,E)，并且给定向图GGG中的任意两个节点vvv和uuu，如果节点uuu和vvv相互可达，即至少存在一条路径可以由节点uuu开始，到节点vvv终止，同时存在至少一条路径可以由节点vvv开始，到节点uuu终止，那么就称该有向图GGG是强连通图。 弱连通图 若至少有一对节点不满足单向连通，但去掉边的方向后从无向图的观点看是连通图，则DDD称为弱连通图。 单向连通图 若每对节点至少有一个方向是连通的，则DDD称为单项连通图。 强连通分支 有向图GGG的极大强连通子图称为该有向图的强连通分支。 出度与入度： 如上图中右图，节点B的出度为2，入度为1。 有向路径： 从x到y有一条有向路径，不一定从y到x存在有向路径； 即使从x到y有，从y到x也有，但这两条路径经过的节点可能完全不同。 A → B ; B → D → E → F → A 有向图的强连通性 强连通分量 一个节点子集和它们之间的边，满足： 第一，如果它有两个或者更多的节点，那么其中任意两个节点之间的都存在两个方向上的有向路径； 第二，不被包含在一个更大得且满足第一个要求的节点集合之中。 尽可能大的双向连通节点子集 在一个有向图中，不可能存在一个节点属于两个不同的强连通分量。 总结： 有向图是描述具有方向性关系的工具。 与（无向）图的几个基本概念的对应关系： 节点 —— 节点 边 —— 有向边 路径（圈） —— 有向路径（有向圈） 连通 —— 强连通 连通分量 —— 强连通分量 二、将Web看成是一个有向图 领结：Web信息结构的一种概貌 Andrei Broder等发现万维网包含一个超大强连通分量SCC，加上其他部分，显示出一种形象的结构 链入，链出，卷须（管道），游离 SCC Furthermore, several studies have suggested that the directed graph connecting web pages has a bowtie shape: there are three major categories of web pages that are sometimes referred to as IN, OUT and SCC. A web surfer can pass from any page in IN to any page in SCC, by following hyperlinks. Likewise, a surfer can pass from page in SCC to any page in OUT. Finally, the surfer can surf from any page in SCC to any other page in SCC. However, it is not possible to pass from a page in SCC to any page in IN, or from a page in OUT to a page in SCC (or, consequently, IN). Notably, in several studies IN and OUT are roughly equal in size, whereas SCC is somewhat larger; most web pages fall into one of these three sets. The remaining pages form into tubes that are small sets of pages outside SCC that lead directly from IN to OUT, and tendrils that either lead nowhere from IN, or from nowhere to OUT. Figure 19.4 illustrates this structure of the Web. source： https://nlp.stanford.edu/IR-book/html/htmledition/the-web-graph-1.html 如何按照”领结“思路，获得一个有向图的几个组成部分？ 简化：只关心SCC，IN和OUT三个部分 假设我们知道某个节点一定在SCC中 给定有向图和其中的一个节点，如何得到包含该节点的强连通分量（SCC），以及相对于这个强连通分量的IN部分和OUT部分。 从某一节点上做广度优先搜索，从111节点进行搜索： FS={1,8,13,14,9,3,4,15,5,16,18,10}FS = \\{ 1, 8, 13, 14, 9, 3, 4, 15, 5, 16, 18, 10\\}FS={1,8,13,14,9,3,4,15,5,16,18,10} 然后，在依据反向图进行搜索： BS={1,4,9,14,13,15,8,12,18,3,7,6,11}BS=\\{1, 4, 9, 14, 13, 15, 8, 12, 18, 3, 7, 6, 11\\}BS={1,4,9,14,13,15,8,12,18,3,7,6,11} 所以，SCC=FS∩BS={1,3,4,8,9,13,14,15,18}SCC = FS \\cap BS = \\{1, 3, 4, 8, 9, 13, 14, 15, 18\\}SCC=FS∩BS={1,3,4,8,9,13,14,15,18} IN=BS−SCC={6,7,11,12}IN = BS - SCC = \\{6, 7, 11, 12\\}IN=BS−SCC={6,7,11,12} OUT=FS−SCC={5,10,16}OUT = FS - SCC = \\{5, 10, 16\\}OUT=FS−SCC={5,10,16} 有向图的“领结”表示 总结： 有向图是一种信息组织的有效形式 将Web看成是一个有向图，人们发现它宏观上像一个“领结”，多次数据实验验证了这个结论。（IN, OUT, SCC） 广度优先搜索，视具体得到“领结”的各个组成部分的基本手段。 三、中枢与权威 搜索引擎关心的基本问题 计算机显示屏只能够显示5-6个结果，典型搜索引擎掌握的网页超过60亿 对用户提交的一个查询，如何从这种海量网页集合中将最可能满足用户需求的少数几个结果找出来，展现在计算机显示屏上？ 传统信息检索（IR）技术要点 基于词语之间的相关性（relevance） 传统应用背景 文档集合：图书，规范的文献 查询：主题词，关键词 查询意图：获取与查询词有关的书籍和文章 用户：图书管理人员 ”查询目标包含查询词“ 是一个合理假设 在形成查询词的时候就有这样的意识 有效利用链接关系蕴含的信息，是搜索引擎超越传统信息检索系统、技术进步的重要标志。 Web page之间的链接有两层含义：关系、描述 反复改进原理 （principle of repeated improvement） 网页的“中枢”与“权威”性 万维网中一篇网页的两面属性。 观念： 被很多网页指向：权威性高，认可度高 被指向很多网页：中枢性强 HITS算法：计算网页的权威值（auth）和中枢值（hub） Hyperlink-Induced Topic Search auth(p)auth(p)auth(p) 和 hub(p)hub(p)hub(p) 的计算方法 输入： 一个有向图 初始化：对于每一个节点 p，auth(p)=1,hub(p)=1auth(p) = 1, hub(p) = 1auth(p)=1,hub(p)=1 利用中枢值更新权威值 对于每一个节点 p，让auth(p)auth(p)auth(p)等于指向 p 的所有节点 q 的hub(q)hub(q)hub(q)之和 利用权威值更新中枢值 对于每一个节点 p，让hub(p)hub(p)hub(p)等于 p 指向的所有节点 q 的auth(q)auth(q)auth(q)之和 重复上述步骤若干（k）次 在搜索引擎领域，auth值或hub值高的网页，分别称为“权威网页”和“中枢网页”。一篇网页可以兼具二者。 归一化与极限 数值随迭代次数递增 Auth 和 hub 值的意义在于相对大小 在每一轮结束后作归一化：值/总和值/总和值/总和 归一化结果随迭代次数趋向于一个极限 相继两次迭代的值不变 极限与初始值无关，即存在“均衡” 总结： 在一个由“引用”或者“推荐”关系构成的信息网络中，每个节点都有两种自然作用：“权威”与“枢纽”（中枢） 这样的作用可以用过“HITS算法”得到量化 HITS算法的基本精神是基于信息网络的结构，在两个量之间交叉进行“反复改进” 四、PageRank： 节点重要度的一种测度 基本要领：每一个节点将自己的值均分给出向邻居，每个节点将从入向邻居收到的值加起来。 PageRank算法基本描述： 输入： 一个有nnn个节点的网络（有向图），设所有节点的 pagerank 初始值为 1n\\frac{1}{n}n1​。 选择操作的步骤数kkk。 按照下列规则，同时对每个节点进行操作，做kkk次： 每个节点将自己当前的 pagerank 值通过出向链接均分传递给所指向的节点 若没有出向链接，则认为传递给自己（或者说保留给自己） 每个节点以从入向链接获得的（包括可能自传的）所有值之和更新它的 pagerank 总结： 在一个由“引用”或者“推荐”关系构成的信息网络中，每个节点的重要性可以认为取决于有多少人推荐，以及推荐人的重要性 这种重要性可通过“PageRank算法“得到量化 PageRank算法的基本精神是基于信息网络的结构，让每个节点不断把自己的重要性分给出向邻居，同时用从入向邻居收到的重要性之和来更新自己。 五、同比缩减与等量补偿 PageRank基本算法在某些结构上的“病态” 从上图去掉(G,A)(G, A)(G,A)和(F,A)(F, A)(F,A) 边，添加 (F,G)(F, G)(F,G) 和 G,A{G, A}G,A 两条边，得到： 此时，F 和 G两个节点显得很“自私”：不断吸收其他节点的价值，但不向外分享。 PageRank的同比缩减与统一补偿原则 同比缩减 在每次运行基本PageRank更新规则后，将每一个节点的PageRank值都乘以一个小于1的比例因子s(0&lt;s&lt;1)s (0&lt;s&lt;1)s(0&lt;s&lt;1)，经验值在0.8~0.9之间。 统一补偿 在每一个节点的PageRank值上统一加上1−sn\\frac{1-s}{n}n1−s​。 这样，既维持了∑PR=1\\sum PR = 1∑PR=1的性质，也防止了PR值过度集中到个别节点。 随机游走：PageRank的另一种等价理解 想象一个人从一篇随机选择的网页开始，然后随机选择其中的链接浏览到下一篇网页，并不断如此进行，称为“随机游走”。 考虑任意一篇网页X，问：经过k步随机游走到达X的概率是多少？ 可以证明：到达X的概率等于运行PageRank基本算法k步得到的值。 随机游走概念稍加修改也可以和同比缩减、统一补偿的PageRank等价。 总结： 信息一旦刻画成一种网络，其中的边经常自然地隐含着一种“推荐”或者“引用”关系，人们可以利用这种关系对信息的作用进行评估： 影响力、重要性、权威性、新颖性…… 先进的评估方法不仅考虑局部结构，而且会考虑全局结构带来的影响（节点特征性质在网络中的传播） HITS算法、PageRank算法 当理想遇到现实 —— 重要现实情况的处理 数据范围问题，退化网络结构问题","link":"/2020/03/12/Social%20computing%204/"},{"title":"Trie字典树","text":"一、字典树 字典树——Trie树，又称为前缀树（Prefix Tree）、单词查找树或键树，是一种多叉树结构。 上图是一棵__Trie__树，表示了关键字集合{“a”, “to”, “tea”, “ted”, “ten”, “i”, “in”, “inn”} 。从上图可以归纳出Trie树的基本性质： 根节点不包含字符，除根节点外的每一个子节点都包含一个字符。 从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串。 每个节点的所有子节点包含的字符互不相同。 通常在实现的时候，会在结点结构中设置一个标志，用来标记该节点处是否构成一个单词（关键字）。 可以看出，Trie树的关键字一般都是字符串，而且Trie树把每个关键字保存在一条路径上，而不是一个节点中。另外，有两个公共前缀的关键字，在Trie树种前缀部分的路径相同。所以Trie又称为前缀树。 二、字典树的优缺点 优点 插入和查询的效率很高，均是O（m），其中m是待插入/查询的字符串长度。 关于查询，有人会说hash表时间复杂度是O（1）不是更快？但是哈希搜索的效率取决于哈希函数的好坏，若一个坏的hash函数导致了很多冲突，效率不一定比Trie树高 Trie树中不同的关键字不会产生冲突。 Trie树中只有在允许一个关键字关联多个值的情况下才有类似hash碰撞发生。 Trie树不用求hash值，对短字符串有更快的速度。通常，求hash值也是需要遍历字符串的。 Trie树可以对关键字按照字典序排序。 字典排序（lexicographical order）是一种对于随机变量形成序列的排序方法。其方法是，按照字母顺序，或者数字小大顺序，由小到大的形成序列。 每一颗Trie树都可以被看做一个简单版的确定有限状态的自动机（DFA，deterministic finite automation），也就是说，对于一个任意给定属于该自动机的状态（①）和一个属于该自动机字母表的字符（②），都可以根据给定的转移函数（③）转到下一个状态。其中： ① 对于Trie树的每一个节点都确定一个自动机的状态。 ② 给定一个属于该自动机字母表的字符，在图中可以看到根据不同字符形成的分支； ③ 从当前节点进入下一层次节点的过程进过状态转移函数得出。 核心思想是：空间换时间，利用字符串的公共前缀来减少无谓的字符串比较以达到提高查询效率的目的。 缺点 当hash函数很好时，Trie树的查找效率低于哈希搜索。 空间消耗大。 三、Trie树的应用 字符串检索 检索、查询功能是Trie树最原始功能，思路就是从根节点开始一个一个字符进行比较。 * 如果沿路比较，发现不同的字符，则表示该字符串在集合中不存在。 * 如果所有的字符全部比较并且完全相同，还需要判断最后一个节点标识位（标记该节点是否为一个关键字）。 词频统计 Trie树常被搜索引擎用于文本词频统计。 思路：为了实现词频统计，我们修改了节点结构，用一个整型变量count来计数。对每一个关键字执行插入操作，若已存在，计数加1，若不存在，插入后count置 1。 、 (1. 2. 都可以用hash table做) 字符串排序 Trie树可以对大量字符串按字典序进行排序，思路也很简单：遍历一次所有关键字，将它们全部插入trie树，树的每个结点的所有儿子很显然地按照字母表排序，然后先序遍历输出Trie树中所有关键字即可。 前缀匹配 例如：找出一个字符串集合中所有以ab开头的字符串。我们只需要用所有字符串构造一个trie树，然后输出以a-&gt;b-&gt;开头的路径上的关键字即可。 trie树前缀匹配常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。 作为辅助结构 如后缀树，AC自动机 有穷自动机参考这里 与哈希表相比 优点： trie数据查找与不完美哈希表（链表实现）在最坏情况下更快；对于trie树，最差为O（m），m为查找字符串的长度；对于不完美哈希表，会有键值冲突（不同键哈希相同），最坏为O（N），N为全部字符产生的个数。典型情况是O（m）用于哈希计算，O（1）用于数据查找。 trie中不同键没有冲突 trie的桶与哈希表用于存储键冲突的桶类似，仅在单个键与多个值关联时需要 当更多的键加入到trie中，无需提供hash方法或改变hash方法 trie通过键为条目提供字母顺序 缺点： trie数据查找在某些情况下（磁盘或随机访问时间远远高于主存）比哈希表慢 当键值为某些类型（如浮点型），前缀链很长且前缀不是特别有意义。 一些trie会比hash表更消耗内存。对于trie，每个字符串的每个字符都要分配内存；对于大多数hash，只需要为整个条目分配一块内存。 与二叉搜索树相比 二叉搜索树，又称二叉排序树，它满足： 任意节点如果左子树不为空，左子树所有节点的值都小于根节点的值； 任意节点如果右子树不为空，右子树所有节点的值都大于根节点的值； 左右子树也都是二叉搜索树； 所有节点的值都不相同。 其实二叉搜索树的优势已经在与查找、插入的时间复杂度上了，通常只有O(log n)，很多集合都是通过它来实现的。在进行插入的时候，实质上是给树添加新的叶子节点，避免了节点移动，搜索、插入和删除的复杂度等于树的高度，属于O(log n)，最坏情况下整棵树所有的节点都只有一个子节点，完全变成一个线性表，复杂度是O(n)。 Trie树在最坏情况下查找要快过二叉搜索树，如果搜索字符串长度用m来表示的话，它只有O(m)，通常情况（树的节点个数要远大于搜索字符串的长度）下要远小于O(n)。 四、实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;#define ALPHABET_SIZE 26typedef struct trie_node{ int count; // 记录该节点代表的单词的个数 trie_node *children[ALPHABET_SIZE]; // 各个子节点 }*trie;trie_node* create_trie_node(){ trie_node* pNode = new trie_node(); pNode-&gt;count = 0; for(int i=0; i&lt;ALPHABET_SIZE; ++i) pNode-&gt;children[i] = NULL; return pNode;}void trie_insert(trie root, char* key){ trie_node* node = root; char* p = key; while(*p) { if(node-&gt;children[*p-&apos;a&apos;] == NULL) { node-&gt;children[*p-&apos;a&apos;] = create_trie_node(); } node = node-&gt;children[*p-&apos;a&apos;]; ++p; } node-&gt;count += 1;}/** * 查询：不存在返回0，存在返回出现的次数 */int trie_search(trie root, char* key){ trie_node* node = root; char* p = key; while(*p &amp;&amp; node!=NULL) { node = node-&gt;children[*p-&apos;a&apos;]; ++p; } if(node == NULL) return 0; else return node-&gt;count;}int main(){ // 关键字集合 char keys[][8] = {&quot;the&quot;, &quot;a&quot;, &quot;there&quot;, &quot;answer&quot;, &quot;any&quot;, &quot;by&quot;, &quot;bye&quot;, &quot;their&quot;}; trie root = create_trie_node(); // 创建trie树 for(int i = 0; i &lt; 8; i++) trie_insert(root, keys[i]); // 检索字符串 char s[][32] = {&quot;Present in trie&quot;, &quot;Not present in trie&quot;}; printf(&quot;%s --- %s\\n&quot;, &quot;the&quot;, trie_search(root, &quot;the&quot;)&gt;0?s[0]:s[1]); printf(&quot;%s --- %s\\n&quot;, &quot;these&quot;, trie_search(root, &quot;these&quot;)&gt;0?s[0]:s[1]); printf(&quot;%s --- %s\\n&quot;, &quot;their&quot;, trie_search(root, &quot;their&quot;)&gt;0?s[0]:s[1]); printf(&quot;%s --- %s\\n&quot;, &quot;thaw&quot;, trie_search(root, &quot;thaw&quot;)&gt;0?s[0]:s[1]); return 0;} 对于Trie树，我们一般只实现插入和搜索操作。这段代码可以用来检索单词和统计词频。 五、Trie树改进 按位树（Btiwise Trie）：原理上和普通Trie树差不多，只不过普通Trie树存储的最小单位是字符，但是Bitwise Trie存放的是位而已。位数据的存取由CPU指令一次直接实现，对于二进制数据，它理论上要比普通Trie树快。 节点压缩 ①分支压缩： 对于稳定的Trie树，基本上都是查找和读取的操作，完全可以把一些分支进行压缩。例如，下图中最右侧分支inn可以直接压缩成一个节点“inn”，而不需要作为一个常规子树存在。Radix树就是根据这个原理来解决Trie树过深的问题。 ②节点映射表：这种方式也是Trie树节点可能几乎完全确定下采用的，针对Trie树节点的每一个状态，如果状态总数重复很多的话，通过一个元素为数字的多维数组（比如Triple Array Trie）来表示，这样存储Trie树本身的空间开销会小一些，虽然引入了额外的映射表。 双数组TRIE树（Double Array Trie） 它在保证Trie树检索速度的前提下，提高空间利用率而提出的一种数据结构，本质上还是一个确定有限自动机。（所谓DFA就是一个能够实现状态专一的自动机，对于一个给定的属于该自动机的状态和一个数据该自动机字符表Σ的字符，它能够根据预先给定的状态转移函数转移到下一个状态。） 对于DAT来说，每个节点代表自动机的一个状态， 根据变量的不同，进行状态转移，当达到结束状态或者无法转移时，完成查询。 参考资料：http://blog.csdn.net/zzran/article/details/8462002 六、Trie树的其他形式 上图主要说明下这些算法数据结构之间的关系。图中黄色部分主要写明了这些算法和数据结构的一些关键点。 图中可以看到这样一些关系：extend-kmp 是kmp的扩展；ac自动机是kmp的多串形式；它是一个有限自动机；而trie图实际上是一个确定性有限自动机；ac自动机，trie图，后缀树实际上都是一种trie；后缀数组和后缀树都是与字符串的后缀集合有关的数据结构；trie图中的后缀指针和后缀树中的后缀链接这两个概念及其一致。 七、Trie树的性能比较 参考博客 http://www.hankcs.com/nlp/performance-comparison-of-several-trie-tree.html 参考资料 Trie树 http://www.raychase.net/1783?replytocom=264917 Trie树 http://blog.csdn.net/v_july_v/article/details/6897097 BitWise Trie http://blog.csdn.net/breeze_gao/article/details/8461856 AC自动机 http://www.cppblog.com/menjitianya/archive/2014/07/10/207604.html","link":"/2016/04/25/Trie%E5%AD%97%E5%85%B8%E6%A0%91/"},{"title":"gpu.js","text":"gpu.js 使用记录 定义GPU 12345const mode = &apos;gpu&apos;;// gpu, cpuconst gpu = new GPU({ mode: mode });console.log(gpu.getMode());// gpu 输出 output： array： [width], [width, height], [width, height, depth] object: { x: width, y: height, z: depth} outputToTexture (Boolean) 值保存到texture中。 floatOutput floatTextures functions 输入 数字 一位数组 二维数组 三维数组 html image array of html image 使用thread 123456789const myFunc = gpu.createKernel(function(image) { const pixel = image[this.thread.y][this.thread.x]; this.color(pixel[0], pixel[1], pixel[2], pixel[3]);}) .setGraphical(true) .setOutput([100]);myFunc([1, 2, 3]);// Result: colorful image 输入[x, y, z] 使用流水线，即在GPU中保存值。 可以调用 outputToTexture: boolean 或者 kernel.setOutputToTexture(true) 12345678const importAsTexture = gpu.createKernel(function(value) { return value[this.thread.y][this.thread.x];}) .setOutput([512, 512]) .setOutputToTexture(true);const texture = importAsTexture([1, 2]);// console.log(texture); 存储在内存中的texture Gpu.js 处理图片 https://github.com/gpujs/gpu.js/issues/278 输出数组 1234const k = gpu.createKernel(function () { return this.thread.x % 2;}).setOutput([6, 2, 1]);console.log(k()); QQ截图20180608103424.png 添加额外的定制函数 addFunction 12345678910gpu.addFunction(function mySuperFunction(a, b) { return a - b;});function anotherFunction(value) { return value + 1;}gpu.addFunction(anotherFunction);const kernel = gpu.createKernel(function(a, b) { return anotherFunction(mySuperFunction(a[this.thread.x], b[this.thread.x]));}).setOutput([20]); 或者添加 setFunctions 12345678function mySuperFunction(a, b) { return a - b;}const kernel = gpu.createKernel(function(a, b) { return mySuperFunction(a[this.thread.x], b[this.thread.x]);}) .setOutput([20]) .setFunctions([mySuperFunction]); 传递常量 constants中定义常量。 12345678910const matMult = gpu.createKernel(function(a, b) { var sum = 0; for (var i = 0; i &lt; this.constants.size; i++) { sum += a[this.thread.y][i] * b[i][this.thread.x]; } return sum;}, { constants: { size: 512 }, output: [512, 512],}); GPU.Input 1234567891011121314151617import GPU, { input } from &apos;gpu.js&apos;;function run() { const gpu = new GPU({ mode: &apos;cpu&apos; }); const opt = { output: [3, 3] }; const kernel = gpu.createKernel(function(values) { return values[this.thread.x] + values[this.thread.y]; }, opt); const gpuInput = input(new Float32Array([2, 4, 6, 1, 3, 5, 8, 10, 12]), [3, 3]); const output = kernel(gpuInput); console.log(output);}run(); in GPU mode: 123456(3) [Array(3), Array(3), Array(3)]0:(3) [4, 6, 8]1:(3) [6, 8, 10]2:(3) [8, 10, 12]length:3__proto__:Array(0) 此方法在cpu 模式中无法使用，主要原因是： Input 的实现中，主要使用了 glsl语言。 https://github.com/gpujs/gpu.js/blob/4173dd9610b9c04fa064e7e2e12b5f066d7eeac7/src/backend/web-gl/kernel.js#L627 That is correct, it just has not yet been implemented. The key difference on GPU over CPU is that at this time on GPU the Array&apos;s are always flat, but there is some architecture in place to help flatten them, which is expensive, but isn&apos;t worth making everyone have to pre-flatten their arrays. GPU.input skips this step, allowing for very fast computation without having to flatten, because the data is pre-flattened. I imagine the best means of which to implement this would be to use input, and then on the CPUFunctionBuilder we&apos;d have an option (or detection?) to simply use them, altering the compiled kernel. So: input1[this.thread.z][this.thread.y][this.thread.x] would become something more like: input1[this.thread.hypotheticalndexOrSomething]. https://github.com/gpujs/gpu.js/issues/243 CPU 、GPU mode 123456789101112131415const gpu = new GPU({ mode: mode });console.log(gpu.getMode());var cpu = new GPU({mode:&apos;cpu&apos;});// var gpu = new GPU({mode:&apos;gpu&apos;});function testFunc(inp) { return inp[this.thread.y][this.thread.x];}const cpuKernel = cpu.createKernel(testFunc).setOutput([3, 3]);const gpuKernel = gpu.createKernel(testFunc).setOutput([3, 3]);console.log(&apos;cpu:&apos;, cpuKernel( [[0,1,2], [3,4,5], [6,7,8]] ) );console.log(&apos;gpu:&apos;, gpuKernel( [[0,1,2], [3,4,5], [6,7,8]] ) ); 如果参数不全，则在cpu中出现未定义，在GPU 中出现其他值。 123456789101112131415const gpu = new GPU({ mode: mode });console.log(gpu.getMode());var cpu = new GPU({mode:&apos;cpu&apos;});// var gpu = new GPU({mode:&apos;gpu&apos;});function testFunc(inp) { return inp[this.thread.y][this.thread.x];}const cpuKernel = cpu.createKernel(testFunc).setOutput([3, 3]);const gpuKernel = gpu.createKernel(testFunc).setOutput([3, 3]);console.log(&apos;cpu:&apos;, cpuKernel( [[0, 212], [1, 12], [2,21]] ) );console.log(&apos;gpu:&apos;, gpuKernel( [[0, 212], [1, 12], [2,21]] ) ); SSSP 算法 https://github.com/pan-long/SSSP-on-GPU/blob/master/bellman_ford_gpu.js 多GPU 支持，取决于运行环境（浏览器是否使用多GPU） https://github.com/gpujs/gpu.js/issues/190 webGL 支持检测： http://alteredqualia.com/tmp/webgl-maxparams-test/ createKernelMap 1234567891011var km = new GPU().createKernelMap([ function add(v1, v2) { return v1 + v2; }, function divide(v1, v2) { return v1 / v2; }], function (a, b, c) { return divide(add(a[this.thread.x], b[this.thread.x]), c[this.thread.x]);}, {output: [3], floatOutput: true});console.log(km([1], [1], [3])); 完整实例： 12345678910111213141516171819202122232425262728const mode = &apos;gpu&apos;;// gpu, cpuconst gpu = new GPU({ mode: mode });console.log(gpu.getMode());const size = 4; // keeping it small for testingconst a = new Float32Array(size);const b = new Float32Array(size);const c = new Float32Array(size);for (let i = 0; i &lt; size; ++i) { a[i] = 0; b[i] = i; c[i] = 2;}const megaKernel = gpu.createKernelMap([ function add(a, b) { return a + b; }, function multiply(a, b) { return a * b; }], function (a, b, c) { return multiply(add(a[this.thread.x], b[this.thread.x]), c[this.thread.x]);});megaKernel.setOutput([ size ]);console.log(megaKernel(a, b, c).result); 输出：float32Array(4) [0, 2, 4, 6]， https://github.com/gpujs/gpu.js/issues/258","link":"/2018/06/08/gpu.js/"},{"title":"pip 安装包指定头文件和静态库目录","text":"开发中遇到的问题 pip 指定include 和lib 目录 在指定目录时需要添加标识 build_ext，例如： sudo pip install --global-option=build_ext --global-option=&quot;-I/usr/local/include/&quot; --global-option=&quot;-L/usr/local/lib&quot; &lt;you package name&gt; 其中-L 指定 lib 文件， 123456789101112131415161718192021222324Options for &apos;build_ext&apos; command: --build-lib (-b) directory for compiled extension modules --build-temp (-t) directory for temporary files (build by-products) --plat-name (-p) platform name to cross-compile for, if supported (default: linux-x86_64) --inplace (-i) ignore build-lib and put compiled extensions into the source directory alongside your pure Python modules --include-dirs (-I) list of directories to search for header files (separated by &apos;:&apos;) --define (-D) C preprocessor macros to define --undef (-U) C preprocessor macros to undefine --libraries (-l) external C libraries to link with --library-dirs (-L) directories to search for external C libraries (separated by &apos;:&apos;) --rpath (-R) directories to search for shared C libraries at runtime --link-objects (-O) extra explicit link objects to include in the link --debug (-g) compile/link with debugging information --force (-f) forcibly build everything (ignore file timestamps) --compiler (-c) specify the compiler type --swig-cpp make SWIG create C++ files (default is C) --swig-opts list of SWIG command line options --swig path to the SWIG executable --user add user include, library and rpath --help-compiler list available compilers https://stackoverflow.com/questions/18783390/python-pip-specify-a-library-directory-and-an-include-directory 基于Pycharm远程调试 https://blog.csdn.net/zhaihaifei/article/details/53691873 https://www.xncoding.com/2016/05/26/python/pycharm-remote.html ​","link":"/2018/04/24/pip/"},{"title":"pip源","text":"Pypi 即Python Package Index，是Python官方管理第三方软件库，目前共有96202个包。Python的软件管理工具包括pip等都是用PyPI作为默认软件源和以来。 Pypi的默认镜像地址是pypi.python.org 镜像地址 Mirror Location # of packages last update pypi.python.org San Francisco, California US 96201 2017-01-08 09:48:24 pypi.douban.com Beijing, Beijing CN 97126 2017-01-08 07:00:14 pypi.fcio.net Oberhausen, Nordrhein-Westfalen DE 97735 2017-01-08 09:45:01 pypi.tuna.tsinghua.edu.cn Beijing, Beijing CN Unavailable mirror.picosecond.org/pypi Fremont, California US Unavailable mirrors.aliyun.com/pypi Hangzhou, Zhejiang CN 97513 2017-01-07 19:01:37 pypi.pubyun.com Changzhou, Jiangsu CN 95514 2017-01-08 09:30:03 mirrors-uk.go-parts.com/python Reston, Virginia US Unavailable mirrors-ru.go-parts.com/python Reston, Virginia US Unavailable mirrors-au.go-parts.com/python Reston, Virginia US Unavailable pypi.mirrors.ustc.edu.cn Hefei, Anhui CN 76240 2017-01-08 04:48:06 2017-01-08 18:09:34 更新 数据来源：https://www.pypi-mirrors.org/ 使用方法 简单使用 pip install -i https://&lt;mirror&gt;/simple &lt;package&gt; or pip install -i http://&lt;mirror&gt;/simple &lt;package&gt; 全局设置 Linux 添加~/.pip/pip.conf文件，内容如下： 12345[global]index-url = https://&lt;mirror&gt;/simple[install]trusted-host=&lt;mirror&gt; Windows 在C:\\Users\\&lt;YourPCName&gt;下建立.pip文件夹，并添加pip.conf文件。 文件内容： 12345[global]index-url = https://&lt;mirror&gt;/simple[install]trusted-host=&lt;mirror&gt; http https任选 easy_install和pip使用方法类似。 参考 https://www.pypi-mirrors.org/ http://mirrors.aliyun.com/help/pypi https://en.wikipedia.org/wiki/Python_Package_Index https://pypi.python.org/pypi","link":"/2017/01/08/pip%E6%BA%90/"},{"title":"冒号课堂笔记(1-4课)","text":"《冒泡课堂：编程范式与OOP思想》读书笔记 1-4 课 编程范式 范式译自英文的paradigm，也有译作典范、范型、范例的。所谓编程范式（programming paradigm），指的是计算机编程的基本风格或典范模式。借用哲学术语，如果说每个编程者都在创造虚拟世界，那么编程范式就是他们置身其中自觉不自觉采用德尔世界观与方法论。 库（lib）与框架（framework） 为保证软件开发快速有效，通常采取： 在宏观管理上选取框架以控制整体的结构与流程；在微观实现上利用库和工具包来解决细节问题。 框架的意义在于使设计者在特定领域的整体设计上不必重新发明轮子；库和工具包的意义在于使开发者摆脱底层编码，专注于特定问题和业务逻辑。 库和工具包是为给程序员带来自由的，框架是为程序员带来约束的。 库和工具包侧重代码重用，框架侧重设计重用。 框架是通过控制反转（IoC）机制控制全局，而库和工具包用callback知识局部的控制反转。程序员牺牲了对应用程序流程的主导权，换来的是更简洁的代码和更高的生产效率。 设计模式是软件的战术思想，架构师软件的战略决策。与框架、库和工具包不同，他们不是软件产品，是软件思想。 设计模式与惯用法都是针对常发问题的解决方法，但前者重设计，后者偏实现。 控制反转（Inversion of Control）是一种软件设计原则，与朝哪个用的用户代码调用可重用库（library）代码不同，IoC倒转控制流方向：由库代码调用用户代码。有人将此比作好莱坞原则：”不要打电话给我们，我们会打给你的”。 命令式编程时冯·诺依曼机运行机制的抽象。它把程序看作由若干行动指令组成的有序列表，并用变量来存储数据，用语句来执行指令。 过程式编程（procedural programming）是指引入了过程（procedure）、函数（function）或子程序（subroutine/subprogram）的命令式编程。 结构化编程时过程式编程的一种原则，其主要思想是：提倡在宏观上采用‘自顶向下’的设计，微观上采用顺序、选择和循环的逻辑结构，摒弃或限制goto语句，以保证程序结构清晰、易于调试和维护。 命令式编程模拟电脑运算，是行动导向（Action-Oriented）的，关键在于定义解法，即“怎么做”，因而算法是显性而目标是隐性的；声明式编程模拟人脑思维，目标驱动（Goal-Driven）的，关键在于描述问题，即“做什么”，因而目标是显性而算法是隐性的。 命令式 → 过程式 → 结构化过程式 声明式 → 函数式，数据流式；逻辑式，约束式；属性式；标记式、规范式等 函数式编程：通过数学函数的表达式变换和计算来求值。 逻辑式编程：通过一系列事实和规则，利用数理逻辑来推导或论证结论。 命令式编程的变量代表抽象化的内存，所存内容可能改变；声明式编程的变量代表抽象化的符号，所指对象一般不会改变。 声明式编程专注问题的分析与表达，而不是算法实现，不用指明执行顺序，一般没有或极少有副作用，也不存在内存管理问题。大大降低了编程的复杂度，也适合并发计算。 函数式语言和逻辑式语言擅长数理逻辑的应用； 命令式语言擅长业务逻辑的，尤其是交互式或事件驱动型应用。 编程是寻求一种机制，将指定的输入转化为指定的输出。 命令式：自动机机制，通过设计指令完成从初始态到最终态的转变； 函数式：数学变换机制，通过设计函数完成从自变量到因变量的计算； 逻辑式：逻辑证明机制，通过逻辑推理完成从题设到结论的证明。 OOP（Object-Oriented programming）是一种计算机编程模式，它将对象作为问题空间的基本元素，利用对象和对象间的相互作用来设计程序。 OOP大多是命令式，也有函数式和逻辑式的OO语言。 OOP的核心思想可以归纳为：以数据为中心组织逻辑，将系统视为相互作用的对象集合，并利用继承与多态来增强可维护性、可扩展性与可重用性。 过程式编程以过程为中心，自顶向下，逐步求精。 对象式编程以数据为中心，自底向上，逐步合并。 过程式程序的世界是君主制，OO程序的世界是民主制。 封装使得对象拥有个体身份，继承使对象拥有家庭身份，多态使得对象拥有社会身份。 并法式编程以进程为导向，以任务为中心，以资源共享与竞争为主线。 并法式编程有助于提高运行效率、充分利用资源、提高软件的响应能力、改善用户体验、保证公平竞争，同时以进程为单位将系统模块化，更加真实地模拟世界。 合理的并发式设计应该做到：软件易于重用、维护和测试；有效地利用资源、优化程序性能；保障进程安全和活性；减少性能损失和复杂度。 范式 体系 模块 模块关系 过程式 君主体系 过程 授命与听命 函数式 数学体系 函数 替换与合成 逻辑式 逻辑体系 断言 归纳与演绎 对象式 民主体系 对象 交流与服务 并发式 生产体系 进程 竞争与合作 STL有3要素：算法（algorithms）、容器（container）和迭代器（iterator） 算法是一系列切实有效的步骤； 容器是数据的集合，可以理解为抽象的数组； 迭代器是算法与容器之间的接口，可以理解为抽象的指针或游标。 算法串联数据，如脊贯肉；数据实体算法，如肉附脊。 泛型编程能够打破静态语言的数据类型之间的壁垒，在不牺牲效率并却类型安全的情况下，最大限度地提到算法的普适性。 泛型变成不仅能泛化算法中涉及的概念（数据类型），还能泛化行为（函数、方法和运算）。 泛型编程是以算法为导向的，以算法为中心，逐渐将其所涉及的概念内涵模糊化、外延扩大化，并将其所涉及的运算抽象化、一般化，从而提高算法的可重用性。 领域特定语言 DSL DSL 一般不会一步到位地编译成机器语言或汇编语言，而是通过现成的编译器生成器（compiler-compiler 或 compiler generator）首先转化为高级语言。这样不仅大大降低了难度，也方便程序的调试。 元编程 Meta-programming 元编程是编写、操纵程序的程序。在传统编程中，运算是动态的，但程序本身是静态的；在元编程中，二者都是动态的。 元编程能够减少手工编程，突破原语言的语法限制，提升语言的抽象级别与灵活性，从而提高程序员的生产效率。 许多开发工具、框架引擎之类的基础软件都有自动生成代码的功能，如许多IDE如Visual Studio、Delphi、Eclipse均能通过向导、拖放控件等方式自动生成源码；Servlet引擎将 JSP转换为Java代码。创造DSL以便高效地处理专门领域业务。自动生成重复代码，动态改变语句、函数、类等。 SoC 就是 Separation of Concerns，即关注点分离；DRY就是Don&apos;t repeat yourself，即尽量减少重复代码。 不良代码通病：① 结构混乱或代码紊乱、松散；② 代码重复。解决此问题就是要做到——抽象与分离原则。 抽象与分解的原则：单一化、正交化。 每个模块职责明确专一，模块之间独立，即高内聚低耦合（high cohesion &amp; low coupling）。 AOP 切面 Aspect 描述的是横切关注点（cross-cutting concerns），是与程序纵向主流执行方向横向正交的关注焦点。 接入点是附加行为——建议（advice）的执行点，切入点（pointcut）是指切入点（join point）结合。这些接入点共享一段插入代码。切入点与建议组成切面（aspect），是模块化的横切关注点。 AOP的实现原理： AOP的实现关键是将advice的代码嵌入到主题程序中，术语称之为编织（weaving）。编织可以分为两种：一种是静态编织，通过修改源码或字节码（bytecode）在编译器（compile-time）、后编译器（post-compile）或加载器（load-time）嵌入代码（元编程、产生式编程实现）；另一种是动态编织，通过代理（proxy）等技术在运行时（run-time）实现嵌入。 AOP实施的3步：切面分解、切面实现和切面合成。 事件驱动 采用警觉式者主动去轮询（polling），行为取决于自身的观察判断，是流程驱动的，符合常规的流程驱动式编程（Flow-Driven Programming）的模式。 采用托付式者被动等通知（notification），行为取决于外来的突发事件，是事件驱动的，符合事件驱动式编程（Event-Driven Programming， aka EDP）的模式。 何为事件？ 事件是已经发生的某种令人关注的事情。在软件中，它一般表现为一个程序的某些信息状态上的变化。 事件分类： 内建事件（built-in event）： 底层事件（low-level event）或原生事件（native event） 在用户图形界面（GUI）系统中，这类事件由鼠标、键盘等硬件设备出发； 语义事件（semantic event） 一般代表用户的行为逻辑，是若干个底层事件的组合。比如鼠标的拖放（drag-and-drop）多表示移动被拖放的对象，由鼠标按下、移动和释放三个底层事件组成。 用户自定义事件（user-defined event）： 虚拟事件（virtual event） 原有内建事件基础上的包装。 此外，事件还有自然事件（natural event）和合成事件（synthetic event）。 事件驱动步骤： 实现事件处理器；注册事件处理器；实现事件循环。 事件驱动式的特征： 被动性与异步性。控制反转导致了事件驱动式编程的****被动性passivity。此外，事件驱动式编程还具有异步性（asynchrony）** 的特征，这是由于事件的不可预测性和随机性决定的。 回调函数（callback） Callback是指能作为参数传递的函数或代码，它允许底层模块调用高层模块，使调用者与被调者从代码上解耦。异步Callback在传入后并不会立即调用，使调用者与被调者从时间上解耦。 在C、CPP中函数指针可以实现callback。此外，抽象类（abstract class）、接口（interface）、CPP中的泛型函子（generic functor）和C#中的委托（delegate）都可以实现callback。 控制反转一般通过callback实现，其目的是降低模块之间的依赖性，从而降低模块的耦合度和复杂度。 依赖反转、控制反转和依赖注射是近义词，它们的主题是控制与依赖，目的是解耦，方法是反转，实现一切的关键是抽象接口。 依赖反转原则（Dependency-Inversion Principle，aka DIP）与控制反转相比更加具体——高层模块不依赖于低层模块，它们都应依赖抽象；抽象不应依赖于细节，细节应该依赖抽象。 依赖注射（Dependency Injection，aka DI）——动态地为一个软件组件提供外部依赖。 软件的可伸缩想（scalability）一般指从容应对工作量增长的能力，常与性能（performance）等指标一起考量。而控制反转的主要作用是降低模块之间的依赖性，从而降低模块的耦合度和复杂度，提高软件的可重用性、柔韧性和可扩展性。 独立是异步的前提，耗时是异步的理由。 观察者模式又称为发行/订阅模式，既是事件驱动式的简化，也是事件驱动式的核心思想。MVC架构是观察者模式在架构设计上的一个应用。 函数式编程中，函数是程序的核心，是头等公民，一般没有货很少有副作用，同时没有显示的内存管理。 函数式编程没有副作用（side affect）的好处： 没有副作用的函数易于重构、调试和单元测试。 代码有效性与函数顺序无关，方便并发处理和优化处理。 没有副作用的函数式是引用透明的（referential transparency），即一个表达式随时可以用它的值来替换，如数学中的函数一样，保证了数学思维的贯彻与运用。 惰性求值是需求驱动的，可以避免不必要的等待和计算。 相比于过程式和OOP，函数式思想过于数学化和抽象化，语言表现力和运行效率也不足。 代码的长度不是衡量软件复杂度的唯一标准。其中，逻辑结构越复杂、越微妙、受需求变化影响越大，软件越难控制和维护。 算法=逻辑+控制 。逻辑式编程将算法中的控制部分大都移交给编程语言，开发人员主要关注算法的核心逻辑。这样大大减轻了开发人员的负担，编码也更加简洁，更具有可维护性和可扩展性。 区别于过程式和函数式，逻辑式没有明显的输入和输出。 逻辑式编程不仅适用于人工智能方面的学术领域，还广泛适用于各种设计知识管理、决策分析等方面的应用领域。 相比于设计模式，编程范式针对问题领域更广泛，提出的思想和方法更为普遍适用、更抽象、更系统。此外， 设计模式重在设计，对语言和工具要求不高，而编程范式要求建立一套抽象机制和方法体系，离不开语言或工具的支持。 编程范式的核心价值在于：突破原有编程方式的某些限制，带来新思维和新方法，从而进一步解放程序员的劳动力。 闭包是一种能保存当初创建时环境变量的函数。它通常以匿名方式存在，多用于函数式编程中，能够让代码结构更加清晰简洁。Java中的匿名函数可以看做是OO化的闭包形式。 所谓迭代学习法，是指在具体知识和抽象理论之间进行增量式的循环学习。 // todo. 继续整理第五课 语言小谈","link":"/2020/05/17/%E5%86%92%E5%8F%B7%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0-1-4/"},{"title":"决策论笔记","text":"决策论概述 决策的内涵 决策是在人们的政治、经济、技术和日常生活中，为了达到预期目的，从所有可供选择的多个方案中，找出最满意方案的一种活动。 狭义决策认为决策就是做决定，单纯强调最终结果。 广义决策认为将管理过程的行为都纳入决策范畴，决策贯穿于整个管理过程中。 决策目标： 决策者希望达到的状态，工作努力的目的。一般而言，在管理决策中决策者追求的当然是利益最大化。 决策准则： 决策判断的标准，备选方案的有效性度量。 决策属性： 决策方案的性能、质量参数、特征和约束，如技术指标、重量、年龄、声誉等，用于评价它达到目标的程度和水平。 科学决策过程：任何科学决策的形成都必须执行科学的决策程序。 决策的基本要素 决策者：决策的主体，一个人或团体。 两个以上可供选择的行动方案，记为djd_jdj​。 状态（事件）：决策实施后可能遇到的自然状况，记为θi\\theta_iθi​。 状态概率：对各状态发生可能性大小进行主观估计，记为P(θi)P(\\theta_i)P(θi​)。 结局（损益）：当决策djd_jdj​实施后遇到的状态θi\\theta_iθi​所产生的的效益（利润）或损失（成本），记为μij\\mu_{ij}μij​，用损益表表示。 损益表 决策的分类 按决策影响范围分类： 战略决策 战术决策 按决策的状态空间分类： 确定型决策： 状态只有一种； 不确定型决策：状态不止一种，且决策者对状态发生的概率未知； 风险型决策：状态不止一种，但决策者对状态发生的概率已知。 按决策的时间分类： 程序决策 非程序决策 半程序决策 按描述方法分类： 定性决策 定量决策 定性与定量相结合 按目标数量分类： 单目标决策 多目标决策 按决策过程的连续性分类： 单级决策 序贯决策 按决策者数量分类： 个人决策 群决策 按问题大小分类： 宏观决策 微观决策 决策的过程 确定目标 收集信息 提出方案 预决策过程 方案优选 决策 决策的模型 决策者 决策方案（属性、目的、目标） 状态 准则 收益 价值观 不确定型决策 不确定型决策：决策者对状态发生的概率一无所知。 A=(aij)A=(a_{ij})A=(aij​)表示iii策略在jjj状态下的收益值，不确定决策方法就是在给定决策矩阵AAA，决策者对状态发生的情况一无所知的情况下如何确定最优决策？ 由于在不确定决策中，各种决策环境是不确定的，所以对于同一个决策问题，用不同的方法求值，将会得到不同的结论，在现实生活中，同一决策问题，决策者偏好不同，也会使得处理相同问题的原则方法不同。 不确定型决策方法 悲观主义准则（maxmin准则） Si∗=max⁡i(min⁡j(aij))S^*_i = \\displaystyle\\max_i(\\min_j(a_{ij}))Si∗​=imax​(jmin​(aij​))，先每行求最小，后各列求最大得最优策略。 乐观主义准则(maxmax准则) Si∗=max⁡i(max⁡j(a∗ij))S^*_i = \\displaystyle\\max_i(\\max_j(a*{ij}))Si∗​=imax​(jmax​(a∗ij))，先每行求最大，后各列求最大得最优策略。 等可能准则 Si∗=max⁡i(∑j=1naijn)S_i^* = \\displaystyle\\max_i(\\sum_{j=1}^n\\frac{a_{ij}}{n})Si∗​=imax​(j=1∑n​naij​​) 先每行求平均值，后各列求最大得最优决策。 最小机会损失准则 先用每列的最大值减去各列元素得到损失矩阵A′A&apos;A′， Si∗=min⁡i(max⁡jaij′)S_i^*=\\displaystyle\\min_i(\\max_ja_{ij}^{&apos;})Si∗​=imin​(jmax​aij′​) 折衷主义准则 先每行分别求最小值、最大值，然后乘上一个乐观系数，以此为标准进行选择。 si∗=max⁡i(αmax⁡j(aij)+(1−α)min⁡j(aij))s_i^*=\\displaystyle\\max_i(\\alpha\\max_j(a_{ij})+(1-\\alpha)\\min_j(a_{ij}))si∗​=imax​(αjmax​(aij​)+(1−α)jmin​(aij​)) 风险型决策 风险型决策：决策者对状态发生概率是已知的。 数学期望方法 Si∗=max⁡i(∑j=1npjaij)S_i^*=\\displaystyle\\max_i(\\sum_{j=1}^n p_j a_{ij})Si∗​=imax​(j=1∑n​pj​aij​) 决策树的组成： 决策节点 状态节点 结果节点（收益） 决策树 □ 表示决策节点。节点中的数字为决策后最优方案的益损期望值。从它引出的分支是方案分支。 ⬭ 表示方案节点。节点中数字为节点号，节点上的数据是该方案的损益期望值。从它引出的分支叫状态分支。在分支上表明状态和出现的概率。 △ 表示结果节点。节点中数字为每一个方案在相应状态下的益损值。 利用决策树进行决策时的两个步骤： 画决策树——从根部到枝部。问题的益损矩阵就是决策树的框图。 决策过程——从枝部到根部。先计算每个行动的益损期望值，再比较各行动方案的值，将最大的期望值保留，同时截去其他方案的分枝。 修正概率方法 贝叶斯决策：开始人们对原来的参数提出了某一个概率分布。后来通过调查又获得许多信息，只要原来的信息不是错误的，则应该用后来的补充信息修正原来的认识。用补充情报改进原来的概率分布。 主观概率：将依据过去的信息或经验由决策者估计的概率称之为主观概率。 先验概率：未收到新信息时根据已有的信息和经验，估计出概率分布称为先验概率。 客观概率：用随机试验确定出的概率称为客观概率。 后验概率：收到新信息，修正后的概率分布称为后验概率。 条件概率：事件B已经发生的条件下，事件A发生的概率，称为事件A在给定B下的条件概率。 P(B∣A)=P(AB)P(A),P(A∣B)=P(AB)P(B)P(B|A)=\\frac{P(AB)}{P(A)}, P(A|B)=\\frac{P(AB)}{P(B)}P(B∣A)=P(A)P(AB)​,P(A∣B)=P(B)P(AB)​ 贝叶斯公式：若A1,A2,…,AnA_1,A_2,\\dots,A_nA1​,A2​,…,An​构成一个完备事件，P(Am)&gt;0P(A_m)&gt;0P(Am​)&gt;0，则对任何概率不为零的时间B，有 P(Am∣B)=P(Am)P(B∣Am)∑iP(Ai)P(B∣Ai),m=1,2,…,nP(A_m|B)=\\frac{P(A_m)P(B|A_m)}{\\displaystyle\\sum_iP(A_i)P(B|A_i)}, \\quad m=1,2,\\dots,nP(Am​∣B)=i∑​P(Ai​)P(B∣Ai​)P(Am​)P(B∣Am​)​,m=1,2,…,n 此公式为后验概率。 效用理论 贝努利（D. Berneulli）首次提出效用概念，他用下图表示出人们对钱财的真实价值的考虑与其钱财拥有量之间的关系，这就是贝努利货币效用函数。 效用是一种相对的指标值，它的大小表示决策者对于风险的态度，对某事物的倾向、偏差等主观因素的强弱程度。 如果每个方案的期望值相等，即用最大期望值决策不合适，可以用最大效用值期望准则。 确定效用曲线的基本方法有两种： 直接提问法，需要决策者回答提问，主观衡量，应用较少； 对比提问法，此方法使用较多。 对比提问法： 设现有A0,A1A_0,A_1A0​,A1​两种方案供选择。$A_0 表示决策者不需要花费任何风险可获收益表示决策者不需要花费任何风险可获收益表示决策者不需要花费任何风险可获收益x_0；而；而；而A_1有两种自然状态，可以概率有两种自然状态，可以概率有两种自然状态，可以概率P获得收益获得收益获得收益x_1，以概率，以概率，以概率(1-P)获得收益获得收益获得收益x_2；且；且；且x_1&gt;x_0&gt;x_2$； 令yiy_iyi​表示效益xix_ixi​的效用值，则x0,x1,x2x_0,x_1,x_2x0​,x1​,x2​的效用值分别用y0,y1,y2y_0,y_1,y_2y0​,y1​,y2​。若在某条件下，决策者认为A0,A1A_0,A_1A0​,A1​两方案等价，则有： Py1+(1−P)y2=y0 Py_1+(1-P)y_2=y_0 Py1​+(1−P)y2​=y0​ 4个数p,x0,x1,x2p,x_0,x_1,x_2p,x0​,x1​,x2​中给定3个，提问第4个变量有决策者决定，求出效用值。 一般采用改进V-M（Von Neumann-Morgenstern）方法，固定P=0.5,x1,x2P=0.5,x_1,x_2P=0.5,x1​,x2​改变x0x_0x0​三次，得出相应的yyy值，确定三点，作出效用曲线。 0.5y(x1)+0.5y(x2)=y(x0) 0.5y(x_1)+0.5y(x_2)=y(x_0) 0.5y(x1​)+0.5y(x2​)=y(x0​) 不同决策者对待风险态度不同，因而会得到不同形状的效用曲线。一般可分为保守型I、中间型II、风险型III，如下图 图中I为保守型，其特点为：当收益指较小时，效用值增加较快；随收益值增大时，效用值增加速度变慢，表明决策者不求大利，谨慎小心、保守。 图中II为中间型，其特点为：收益指与效用值成正比，表明决策者完全按机遇办事，心平气和。 图中III为风险型，其特点与I保守型恰好相反，当收益较小时，效用值增加较慢；随收益值增大时，效用值增加速度变快，表明决策者对增加收益反应敏感，愿冒较大风险，谋求大利，不怕冒险。","link":"/2020/05/14/%E5%86%B3%E7%AD%96%E8%AE%BA%E7%AC%94%E8%AE%B0/"},{"title":"字典树Trie2","text":"接着上一篇字典树结构的讲解，我们接着使用C++和Python来实现字典树。 一、LeetCode的字典树 在LeetCode 208 要求实现字典树。 Implement a trie with insert, search, and startsWith methods. Note: You may assume that all inputs are consist of lowercase letters a-z. 二、Python实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100# coding:utf-8&quot;&quot;&quot;Implement a trie with insert, search, and startsWith methods.Note:You may assume that all inputs are consist of lowercase letters a-z.Subscribe to see which companies asked this question&quot;&quot;&quot;class TrieNode(object): def __init__(self): &quot;&quot;&quot; Initialize your data structure here. &quot;&quot;&quot; self.data = {} self.is_word = Falseclass Trie(object): def __init__(self): self.root = TrieNode() def insert(self, word): &quot;&quot;&quot; Inserts a word into the trie. :type word: str :rtype: void &quot;&quot;&quot; node = self.root for letter in word: child = node.data.get(letter) if not child: node.data[letter] = TrieNode() node = node.data[letter] node.is_word = True def search(self, word): &quot;&quot;&quot; Returns if the word is in the trie. :type word: str :rtype: bool &quot;&quot;&quot; node = self.root for letter in word: node = node.data.get(letter) if not node: return False return node.is_word # 判断单词是否是完整的存在在trie树中 def starts_with(self, prefix): &quot;&quot;&quot; Returns if there is any word in the trie that starts with the given prefix. :type prefix: str :rtype: bool &quot;&quot;&quot; node = self.root for letter in prefix: node = node.data.get(letter) if not node: return False return True def get_start(self, prefix): &quot;&quot;&quot; Returns words started with prefix :param prefix: :return: words (list) &quot;&quot;&quot; def _get_key(pre, pre_node): words_list = [] if pre_node.is_word: words_list.append(pre) for x in pre_node.data.keys(): words_list.extend(_get_key(pre + str(x), pre_node.data.get(x))) return words_list words = [] if not self.starts_with(prefix): return words if self.search(prefix): words.append(prefix) return words node = self.root for letter in prefix: node = node.data.get(letter) return _get_key(prefix, node)# Your Trie object will be instantiated and called as such:trie = Trie()trie.insert(&quot;somestring&quot;)trie.insert(&quot;somebody&quot;)trie.insert(&quot;somebody1&quot;)trie.insert(&quot;somebody3&quot;)print trie.search(&quot;key&quot;)print trie.search(&quot;somebody3&quot;)print trie.get_start(&apos;some&apos;) 输出 123456# print trie.search(&quot;key&quot;)False# print trie.search(&quot;somebody3&quot;)True# print trie.get_start(&apos;some&apos;)[&apos;somestring&apos;, &apos;somebody&apos;, &apos;somebody1&apos;, &apos;somebody3&apos;] 采用Class来实现字典树：https://github.com/bdimmick/python-trie/blob/master/trie.py 三、C++实现","link":"/2016/04/26/%E5%AD%97%E5%85%B8%E6%A0%91Trie2/"},{"title":"算法数学基础 - 2","text":"算法数学基础 - 2 函数渐近界的定理 定理1 设fff和 ggg是定义域为自然数集合的函数： （1）如果lim⁡n→∞f(n)/g(n)\\lim\\limits_{n\\rightarrow\\infty}f(n)/g(n)n→∞lim​f(n)/g(n)存在，并且等于某个常数c&gt;0c&gt;0c&gt;0，那么f(n)=Θ(g(n))f(n)=\\Theta(g(n))f(n)=Θ(g(n))。 （2）如果lim⁡n→∞f(n)/g(n)=0\\lim\\limits_{n\\rightarrow\\infty}f(n)/g(n)=0n→∞lim​f(n)/g(n)=0，那么f(n)=o(g(n))f(n)=o(g(n))f(n)=o(g(n))。 （3）如果lim⁡n→∞f(n)/g(n)=+∞\\lim\\limits_{n\\rightarrow\\infty}f(n)/g(n)=+\\inftyn→∞lim​f(n)/g(n)=+∞，那么f(n)=ω(g(n))f(n)=\\omega(g(n))f(n)=ω(g(n))。 推理1 → 多项式函数的阶低于指数函数的阶，nd=o(rn),r&gt;1,d&gt;0n^d=o(r^n),r&gt;1,d&gt;0nd=o(rn),r&gt;1,d&gt;0。 推理2 →对数函数的阶低于幂函数的阶，ln⁡n=o(nd),d&gt;0\\ln n=o(n^d),d&gt;0lnn=o(nd),d&gt;0。 定理2 设函数fff，ggg，hhh的定义域为自然数集合， （1）如果f=O(g)f=O(g)f=O(g)且g=O(h)g=O(h)g=O(h)，那么f=O(h)f=O(h)f=O(h)； （2）如果f=Ω(g)f=\\Omega(g)f=Ω(g)且g=Ω(h)g=\\Omega(h)g=Ω(h) ，那么f=Ω(h)f=\\Omega(h)f=Ω(h)； （3）如果f=Θ(g)f=\\Theta(g)f=Θ(g)且g=Θ(h)g=\\Theta(h)g=Θ(h)，那么f=Θ(h)f=\\Theta(h)f=Θ(h)。 函数的阶之间的关系具有传递性。 定理3 假设函数fff和ggg的定义域为自然数集，若对某个其他函数hhh，有f=O(h)f=O(h)f=O(h)和g=O(h)g=O(h)g=O(h)，那么f+g=O(h)f+g=O(h)f+g=O(h)。 该定理可以推广到有限个函数。即算法由有限步骤构成，若每一步的时间复杂度函数的上界都是h(n)h(n)h(n)，那么该算法的时间复杂度函数可以写作O(h(n))O(h(n))O(h(n))。在常数步的情况下取最高阶函数即可。 几种重要函数的性质 基本函数类 至少指数级：2n,3n,n! ,…2^n,3^n,n!~,\\dots2n,3n,n! ,… 多项式级：n,n2,nlog⁡n,n12,…n,n^2,n\\log n,n^{\\frac{1}{2}},\\dotsn,n2,nlogn,n21​,… 对数多项式级：log⁡n,log⁡2n,log⁡log⁡n,…\\log n, \\log^2n,\\log\\log n,\\dotslogn,log2n,loglogn,… 对数函数 符号： log⁡n=log⁡2n\\log n = \\log_2nlogn=log2​n log⁡kn=(log⁡n)k\\log^kn=(\\log n)^klogkn=(logn)k log⁡log⁡n=log⁡(log⁡n)\\log \\log n=\\log(\\log n)loglogn=log(logn) 性质： （1）log⁡2n=Θ(log⁡ln)\\log_2n=\\Theta(\\log_ln)log2​n=Θ(logl​n) （2）log⁡bn=o(nα),(α&gt;0)\\log_bn=o(n^\\alpha), (\\alpha&gt;0)logb​n=o(nα),(α&gt;0) （3）alog⁡bn=nlog⁡baa^{\\log_bn}=n^{\\log_ba}alogb​n=nlogb​a 指数函数与阶乘 Stirling公式 n!=2πn(ne)n(1+Θ(1n))n!=\\sqrt{2\\pi n}(\\frac{n}{e})^n(1+\\Theta(\\frac{1}{n}))n!=2πn​(en​)n(1+Θ(n1​)) n!=o(nn)n!=o(n^n)n!=o(nn) n!=ω(2n)n!=\\omega(2^n)n!=ω(2n) log⁡(n!)=Θ(nlog⁡n)\\log(n!)=\\Theta(n\\log n)log(n!)=Θ(nlogn) 取整函数 定义： ⌊x⌋\\lfloor x\\rfloor⌊x⌋：表示小于等于xxx的最大整数 ⌈x⌉\\lceil x\\rceil⌈x⌉：表示大于等于xxx的最小整数 举例： ⌊2.6⌋=2,⌈2.6⌉=3,⌊2⌋=⌈2⌉=2\\lfloor 2.6\\rfloor=2, \\lceil 2.6\\rceil=3,\\lfloor 2\\rfloor=\\lceil 2\\rceil=2⌊2.6⌋=2,⌈2.6⌉=3,⌊2⌋=⌈2⌉=2 应用：二分搜索 输入数组长度nnn，中位数位置：⌊n/2⌋\\lfloor n/2\\rfloor⌊n/2⌋，与中位数比较后子问题大小：⌊n/2⌋\\lfloor n/2\\rfloor⌊n/2⌋ 性质 （1）x−1&lt;⌊x⌋≤x≤⌈x⌉&lt;x+1x-1&lt;\\lfloor x\\rfloor \\le x \\le \\lceil x\\rceil &lt; x+1x−1&lt;⌊x⌋≤x≤⌈x⌉&lt;x+1 （2）⌊x+n⌋=⌊x⌋+n,⌈x+n⌉=⌈x⌉+n,n为整数\\lfloor x+n \\rfloor=\\lfloor x\\rfloor+n,\\lceil x+n\\rceil=\\lceil x\\rceil+n, n为整数⌊x+n⌋=⌊x⌋+n,⌈x+n⌉=⌈x⌉+n,n为整数 （3）⌈n2⌉+⌊n2⌋=n\\lceil \\frac{n}{2}\\rceil+\\lfloor \\frac{n}{2}\\rfloor=n⌈2n​⌉+⌊2n​⌋=n （4）⌈⌈na⌉b⌉=⌈nab⌉,⌊⌊na⌋b⌋=⌊nab⌋\\lceil \\frac{\\lceil\\frac{n}{a} \\rceil}{b}\\rceil=\\lceil\\frac{n}{ab} \\rceil, \\lfloor \\frac{\\lfloor \\frac{n}{a}\\rfloor}{b}\\rfloor =\\lfloor \\frac{n}{ab}\\rfloor⌈b⌈an​⌉​⌉=⌈abn​⌉,⌊b⌊an​⌋​⌋=⌊abn​⌋ 按照阶排序 22n,n!,n2n,(3/2)n,(log⁡n)log⁡n=nlog⁡log⁡n,n3,log⁡(n!)=Θ(nlog⁡n),n=2log⁡n,log⁡2n,log⁡n,log⁡n,log⁡log⁡n,n1/log⁡n=1 2^{2^n},\\quad n!,\\quad n2^n,\\quad (3/2)^n,\\quad (\\log n)^{\\log n} =n^{\\log\\log n}, \\\\ n^3,\\quad \\log(n!)=\\Theta(n\\log n),\\quad n=2^{\\log n}, \\\\ \\log^2n,\\quad \\log n,\\quad \\sqrt{\\log n}, \\quad \\log\\log n, \\\\ n^{1/\\log n}=1 22n,n!,n2n,(3/2)n,(logn)logn=nloglogn,n3,log(n!)=Θ(nlogn),n=2logn,log2n,logn,logn​,loglogn,n1/logn=1 来源 北京大学-算法设计与分析","link":"/2020/05/13/%E7%AE%97%E6%B3%95%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-2/"},{"title":"算法数学基础 - 3","text":"算法数学基础 - 3 数列求和公式 等差、等比数列与调和级数 ∑k=1nak=n(a1+an)2∑k=0naqk=a(1−qn+1)1−q,∑k=0∞aqk=a1−q(q&lt;1)∑k=1n1k=ln⁡n+O(1) \\displaystyle\\sum_{k=1}^{n}a_k=\\frac{n(a_1+a_n)}{2} \\\\ \\sum_{k=0}^{n}aq^k=\\frac{a(1-q^{n+1})}{1-q}, \\sum_{k=0}^{\\infty}aq^k=\\frac{a}{1-q}(q&lt;1) \\\\ \\sum_{k=1}^{n}\\frac{1}{k}=\\ln n+O(1)\\\\ k=1∑n​ak​=2n(a1​+an​)​k=0∑n​aqk=1−qa(1−qn+1)​,k=0∑∞​aqk=1−qa​(q&lt;1)k=1∑n​k1​=lnn+O(1) 递推方程 设序列a0,a1,…,an,…a_0,a_1,\\dots,a_n,\\dotsa0​,a1​,…,an​,…简记为{an}\\{a_n\\}{an​}，一个把ana_nan​与某些个ai(i&lt;n)a_i(i&lt;n)ai​(i&lt;n)联系起来叫做关于序列{an}\\{a_n\\}{an​}的递推方程。 迭代法求解递推方程 迭代法： 不断用递推方程的右部替换左部 每次替换，随着nnn的降低在和式中多出一项 直到出现初值停止迭代 将初值并入对和式求和 可用数学归纳法验证解的正确性 换元迭代： 将对nnn的递推式换成对其他变元kkk的递推式 对kkk直接迭代 将解（关于kkk的函数）转换成为关于nnn的函数 差消法化简高阶递推方程 递归树 递归树： 递归树是迭代计算的模型； 递归树的生成过程与迭代过程一致； 递归树上所有恰好是迭代之后产生和式中的项； 对递归树上的项求和就是迭代后方程的解。 迭代在递归树中的表示 如果递归树某结点标记为W(m)W(m)W(m)， W(m)=W(m1)+⋯+W(mt)+f(m)+⋯+g(m),m1,…,mt&lt;mW(m)=W(m_1)+\\dots+W(m_t)\\\\ +f(m)+\\dots+g(m), m_1,\\dots,m_t&lt;mW(m)=W(m1​)+⋯+W(mt​)+f(m)+⋯+g(m),m1​,…,mt​&lt;m 其中，W(m1),…,W(mt)W(m_1),\\dots,W(m_t)W(m1​),…,W(mt​)称为函数项。 递归树的生成规则 初始，递归树只有根节点，其值为W(n)W(n)W(n) 不断继续下述过程： 将函数项叶节点的迭代式W(m)W(m)W(m)表示成二层子树 用该子树替换该叶节点 继续递归树的生成，直到树中无函数项（只有初值）为止。 主定理及其证明 主定理的应用背景 求解地推方程 T(n)=aT(n/b)+f(n)T(n)=aT(n/b)+f(n)T(n)=aT(n/b)+f(n) aaa ： 归约后的子问题个数 n/bn/bn/b：归约后子问题的规模 f(n)f(n)f(n)：归约过程及组合子问题的解的工作量 二分检索：T(n)=T(n/2)+1T(n)=T(n/2)+1T(n)=T(n/2)+1 二分归并排序：T(n)=2T(n/2)+n−1T(n)=2T(n/2)+n-1T(n)=2T(n/2)+n−1 主定理：设a≥1,b&gt;1a\\ge1,b&gt;1a≥1,b&gt;1为常数，f(n)f(n)f(n)为函数，T(n)T(n)T(n)为非负整数，且T(n=aT(n/b)+f(n)T(n=aT(n/b)+f(n)T(n=aT(n/b)+f(n)，则 若f(n)=O(nlog⁡ba−ϵ),ϵ&gt;0f(n)=O(n^{\\log_ba-\\epsilon}),\\epsilon&gt;0f(n)=O(nlogb​a−ϵ),ϵ&gt;0，那么T(n)=Θ(nlog⁡ba)T(n)=\\Theta(n^{\\log_ba})T(n)=Θ(nlogb​a) 若f(n)=Θ(nlog⁡ba)f(n)=\\Theta(n^{\\log_ba})f(n)=Θ(nlogb​a)，那么T(n)=Θ(nlog⁡balog⁡n)T(n)=\\Theta(n^{\\log_ba}\\log n)T(n)=Θ(nlogb​alogn) 若f(n)=Ω(nlog⁡ba+ϵ,ϵ&gt;0)f(n)=\\Omega(n^{\\log_ba+\\epsilon},\\epsilon&gt;0)f(n)=Ω(nlogb​a+ϵ,ϵ&gt;0)，且对于某个常数c&lt;1c&lt;1c&lt;1和充分大的nnn有af(n/b)≤cf(n)af(n/b)\\le cf(n)af(n/b)≤cf(n)，那么T(n)=Θ(f(n))T(n)=\\Theta(f(n))T(n)=Θ(f(n)) 主定理的应用 求解递推方程 求解递推方程T(n)=9T(n/3)+nT(n)=9T(n/3)+nT(n)=9T(n/3)+n 解 递推方程中的 a=9,b=3,f(n=n)a=9,\\quad b=3,\\quad f(n=n)a=9,b=3,f(n=n) nlog⁡39=n2,f(n)=O(nlog39−1)n^{\\log_39}=n^2,\\quad f(n)=O(n^{log_39-1})nlog3​9=n2,f(n)=O(nlog3​9−1) 相当于主定理case1，其中ϵ=1\\epsilon =1ϵ=1 根据定理得到 T(n)=Θ(n2)T(n)=\\Theta(n^2)T(n)=Θ(n2) 求解递推方程 T(n)=T(2n/3)+1T(n)=T(2n/3)+1T(n)=T(2n/3)+1 解 上述递推方程中 a=1,b=3/2,f(n)=1,nlog⁡3/21=n0=1a=1, b=3/2,f(n)=1,n^{\\log_{3/2}1}=n^0=1a=1,b=3/2,f(n)=1,nlog3/2​1=n0=1 相当于主定理的Case2， 根据定理得到T(n)=Θ(log⁡n)T(n)=\\Theta(\\log n)T(n)=Θ(logn) 求解递推方程 T(n)=3T(n/4)+nlog⁡nT(n)=3T(n/4)+n\\log nT(n)=3T(n/4)+nlogn 解 上述递推方程中的 a=3,b=4,f(n)=nlog⁡na=3,b=4,f(n)=n\\log na=3,b=4,f(n)=nlogn nlog⁡n=Ω(nlog⁡43+ϵ)=Ω(n0.793+ϵ)n\\log n=\\Omega(n^{\\log_43+\\epsilon})=\\Omega(n^{0.793+\\epsilon})nlogn=Ω(nlog4​3+ϵ)=Ω(n0.793+ϵ) 取ϵ=0.2\\epsilon=0.2ϵ=0.2即可。 条件验证： 要使af(n/b)≤cf(n)af(n/b)\\le cf(n)af(n/b)≤cf(n)成立，代入f(n)=nlog⁡nf(n)=n\\log nf(n)=nlogn，得到 3(n/4)log⁡(n/4)≤cnlog⁡n3(n/4)\\log(n/4)\\le cn\\log n3(n/4)log(n/4)≤cnlogn 只要c≥3/4c\\ge 3/4c≥3/4，上述不等式可以对所有充分大的nnn成立。相当于Case3。 因此有 T(n)=Θ(f(n))=Θ(nlog⁡n)T(n)=\\Theta(f(n))=\\Theta(n\\log n)T(n)=Θ(f(n))=Θ(nlogn) 递归算法分析： 二分搜索 W(n)=W(n/2)+1,W(1)=1a=1,b=2,nlog⁡21=1,f(n)=1W(n)=W(n/2)+1,W(1)=1\\quad a=1,b=2,n^{\\log_21}=1, f(n)=1W(n)=W(n/2)+1,W(1)=1a=1,b=2,nlog2​1=1,f(n)=1， 属于Case2，W(n)=Θ(log⁡n)W(n)=\\Theta(\\log n)W(n)=Θ(logn) 二分归并排序 W(n)=2W(n/2)+n−1,W(1)=0,a=2,b=2,nlog⁡22=n,f(n)=n−1W(n)=2W(n/2)+n-1, W(1)=0, \\quad a=2,b=2,n^{\\log_22}=n,f(n)=n-1W(n)=2W(n/2)+n−1,W(1)=0,a=2,b=2,nlog2​2=n,f(n)=n−1 属于Case2，W(n)=Θ(nlog⁡n)W(n)=\\Theta(n\\log n)W(n)=Θ(nlogn) 不能使用主定理的例子： 求解 T(n)=2T(n/2)+nlog⁡nT(n)=2T(n/2)+n\\log nT(n)=2T(n/2)+nlogn 解：a=b=2,nlog⁡ba=n,f(n)=nlog⁡na=b=2,n^{\\log_ba}=n,f(n)=n\\log na=b=2,nlogb​a=n,f(n)=nlogn 不存在ϵ&gt;0\\epsilon &gt;0ϵ&gt;0 使右式成立 nlog⁡n=Ω(n1+ϵ)n\\log n = \\Omega(n^{1+\\epsilon})nlogn=Ω(n1+ϵ)， 不存在c&lt;1c&lt;1c&lt;1使af(n/b)≤cf(n)af(n/b)\\le cf(n)af(n/b)≤cf(n)对所有充分大的nnn成立 2(n/2)log⁡(n/2)=n(log⁡n−1)≤cnlog⁡n2(n/2)\\log(n/2)=n(\\log n-1)\\le cn\\log n2(n/2)log(n/2)=n(logn−1)≤cnlogn 递归树求解： T(n)=nlog⁡n+n(log⁡n−1)+n(log⁡n−2)+⋯+n(log⁡n−k+1)=(nlog⁡n)log⁡n−n(1+2+⋯+k−1)=nlog⁡2n−nk(k−1)/2=O(nlog⁡2n) T(n) = n\\log n+ n(\\log n-1)+ n(\\log n-2) \\\\ + \\dots +n(\\log n-k+1) \\\\ = (n\\log n)\\log n - n(1+2+\\dots+k-1) \\\\ = n\\log^2n-nk(k-1)/2 = O(n\\log^2n) T(n)=nlogn+n(logn−1)+n(logn−2)+⋯+n(logn−k+1)=(nlogn)logn−n(1+2+⋯+k−1)=nlog2n−nk(k−1)/2=O(nlog2n) // todo: 继续阅读《具体数学》第一章递推式与第二章和式。","link":"/2020/05/15/%E7%AE%97%E6%B3%95%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-3/"},{"title":"算法数学基础 - 1","text":"算法研究的主要内容 计算复杂性理论（Computational complexity theory） 常见问题： 货郎问题 （NP-hard 问题） 0-1背包问题 问题的解为0-1向量 &lt;X1,X2,...,Xn&gt;&lt;X_1,X_2,...,Xn_&gt;&lt;X1​,X2​,...,Xn&gt;​ 双机调度问题 NP-hard问题 问题有数千个，大量存在于各个领域； 至今未找到有效算法：现有算法的运行时间是输入规模的指数或更高阶函数；、 至今没有人能够证明对于这类问题存在多项式时间算法； 是否存在多项式时间算法等价于存在有效计算的边界 程序 = 算法 + 数据结构 好的算法： 提高求解问题的效率；节省存储空间 算法的研究目标： 问题 → 建模并寻找算法 （算法技术设计） 算法 → 算法的评价 （算法分析方法） 算法类 → 问题复杂度的估计 （问题复杂度分析） 问题类 → 能够求解的边界 （计算复杂性理论） NP完全理论 问题复杂度： 以排序算法（插入、冒泡、快排、堆排、归并） 哪个个排序算法效率高？ 是否可以找到更好的排序算法？ 排序问题的计算难度如何？ 其他问题的计算复杂度 问题计算复杂度估计方法 算法设计与分析（调度问题、背包问题和投资问题） 问题建模？对输入参数和解给出形式化或半形式化的描述。 设计算法：采用什么算法设计技术？ 正确性：这个方法是否对所有实例都得到最优解？如何证明？如果不是，能否找到反例？ 分析算法——效率 算法的相关概念 问题及实例 问题：需要回答的一般性提问，通常含有若干参数 问题描述： 定义问题参数（集合、变量、函数、序列等）； 说明每个参数的取值范围及参数间的关系； 定义问题的解； 说明解满足的条件（优化目标或约束条件） 问题实例 参数的每一组赋值可以得到问题的实例 什么是算法？ 算法即有限条指令的序列，这个指令序列确定了解决某个问题的一系列运算或操作。 算法A解问题P： 把问题P的任何实例作为算法A的输入 每步计算都是确定性的 能够在有限步停机 输出该实例的正确的解 算法的表示 （伪代码） 赋值语句： ← 分支语句：if ... then ... [else...] 循环语句：while, for, repeat until 转向语句：goto 输出语句：return 调用：直接写过程的名字 注释：//.. 算法时间复杂度定义？ 算法时间复杂度：针对指定的基本运算，计数算法所做的运算次数。 基本运算：比较、加法、乘法、置指针、交换…… 排序：元素之间的比较 检索：被检索元素与数组元素的比较 整数乘法：每位数字相乘（位乘）1次m位和n位整数相乘要做mn次位乘 矩阵相乘：每对元素乘1次 i×j 矩阵与j×k矩阵相乘要做ijk次乘法 图的遍历：置指针 …… 输入规模：输入串编码长度 通常用下述参数度量：数组元素多少，调度问题的任务个数，图的顶点数与边数等。 排序：数组元素个数n 检索：被检索数组的元素个数n 整数乘法：两个整数的位数 m，n 矩阵相乘：矩阵的行列数i,j,k 图的遍历：图的顶点数n，边数m …… 算法基本运算次数可表示为输入规模的函数 给定问题和基本运算决定了一个算法类。 时间复杂度函数的表示：函数渐近的界 对于相同输入规模的不同实例，算法的基本运算次数也不一样，可以定义为两种时间复杂度。 最坏情况下的时间复杂度 W(n)W(n)W(n) 平均情况下的时间复杂度A(n)A(n)A(n) 设SSS是规模为nnn的实例集，实例I∈SI \\in SI∈S的概率为PIP_IPI​，算法对实例III执行的基本运算次数为tIt_ItI​。 A(n)=∑I∈SPItI A(n) = \\sum_{I \\in S} P_It_I A(n)=I∈S∑​PI​tI​ 有关函数渐近的界的描述 大O符号 定义：设fff和ggg是定义域为自然数集NNN上的函数。若存在正数ccc和n0n_0n0​，使得对一切n≥n0n \\ge n_0n≥n0​有 0≤f(n)≤cg(n)0 \\le f(n) \\le c g(n)0≤f(n)≤cg(n) 成立，则称f(n)f(n)f(n)的渐近界上界是g(n)g(n)g(n)，记作f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n))。 举例： 设f(n)=n2+nf(n)=n^2+nf(n)=n2+n，则 f(n)=O(n2)f(n)=O(n^2)f(n)=O(n2)，取c=2,n0=1c=2,n_0=1c=2,n0​=1即可；f(n)=O(n3)f(n)=O(n^3)f(n)=O(n3)，取c=1,n0=2c=1,n_0=2c=1,n0​=2即可。 注意： f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n))，f(n)f(n)f(n)的阶不高于g(n)g(n)g(n)的阶； 可能存在多个正数ccc，只要指出一个即可； 对前面有限个值可以不满足不等式； 对于常函数可以写作O(1)O(1)O(1)。 大Ω符号 定义：设fff和ggg是定义域为自然数集NNN上的函数。若存在正数ccc和n0n_0n0​，使得对一切n≥n0n \\ge n_0n≥n0​ 有 0≤cg(n)≤f(n)0 \\le cg(n) \\le f(n)0≤cg(n)≤f(n) 成立，则称f(n)f(n)f(n)的渐近的下界是g(n)g(n)g(n)，记作 f(n)=Ω(g(n))f(n) = \\Omega(g(n))f(n)=Ω(g(n))。 举例： 设f(n)=n2+nf(n)=n^2+nf(n)=n2+n，则f(n)=Ω(n2)f(n)=\\Omega(n^2)f(n)=Ω(n2)，取c=1,n0=1c=1,n_0=1c=1,n0​=1即可；f(n)=Ω(100n)f(n)=\\Omega(100n)f(n)=Ω(100n)，取c=1/100,n0=1c=1/100,n_0=1c=1/100,n0​=1即可。 注意： f(n)=Ω(g(n))f(n)=\\Omega(g(n))f(n)=Ω(g(n))，f(n)f(n)f(n)的阶不低于g(n)g(n)g(n)的阶（下界）； 可能存在多个正数ccc，指出一个即可； 对前面有限个nnn值可以不满足上述不等式。 小o符号 定义：设fff和ggg是定义域为自然数集NNN上的函数。若对于任意正数ccc都存在n0n_0n0​，使得对一切n≥n0n \\ge n_0n≥n0​ 有0≤f(n)&lt;cg(n)0 \\le f(n) &lt; cg(n)0≤f(n)&lt;cg(n)成立，则记作 f(n)=o(g(n))f(n)=o(g(n))f(n)=o(g(n))。 举例： f(n)=n2+nf(n)=n^2+nf(n)=n2+n，则f(n)=o(n3)f(n)=o(n^3)f(n)=o(n3), 当 c≥1c\\ge1c≥1显然成立，因为n2+n&lt;cn3,(n0=2)n^2+n&lt;cn^3,(n_0=2)n2+n&lt;cn3,(n0​=2); 当1&gt;c&gt;01&gt;c&gt;01&gt;c&gt;0，取n0&gt;┌2/c┐n_0&gt;\\ulcorner2/c\\urcornern0​&gt;┌2/c┐即可。因为cn≥cn0≥2,(n≥n0)cn\\ge cn_0 \\ge 2, (n\\ge n_0)cn≥cn0​≥2,(n≥n0​)， n2+n&lt;2n2&lt;cn3n^2+n&lt;2n^2&lt;cn^3n2+n&lt;2n2&lt;cn3成立。 注意： f(n)=o(g(n))f(n)=o(g(n))f(n)=o(g(n))，f(n)f(n)f(n)的阶低于g(n)g(n)g(n)的阶； 对于不同的正数ccc，n0n_0n0​不一样，ccc越小n0n_0n0​越大； 对前面有限个nnn值可以不满足不等式。 小ω符号 定义：设fff和ggg是定义域为自然数集NNN上的函数。若对于任意正数ccc都存在n0n_0n0​，使得对一切n≥n0n \\ge n_0n≥n0​有 0≤cg(n)&lt;f(n)0 \\le cg(n) &lt; f(n)0≤cg(n)&lt;f(n) 成立，则记作 f(n)=ω(g(n))f(n) = \\omega(g(n))f(n)=ω(g(n))。 举例： 设f(n)=n2+nf(n)=n^2+nf(n)=n2+n，则f(n)=ω(n)f(n)=\\omega(n)f(n)=ω(n)。不能写f(n)=ω(n2)f(n)=\\omega(n^2)f(n)=ω(n2)，因为取c=2c=2c=2，不存在n0n_0n0​使得对一切n≥n0n\\ge n_0n≥n0​有下式成立 cn2=2n2&lt;n2+ncn^2=2n^2&lt;n^2+ncn2=2n2&lt;n2+n。 注意： f(n)=ω(g(n))f(n)=\\omega (g(n))f(n)=ω(g(n))，f(n)f(n)f(n)的阶高于g(n)g(n)g(n)的阶（下界)； 对于不同的正数ccc，n0n_0n0​不等，ccc越大n0n_0n0​越大； 对前面有限个nnn值可以不满足不等式。 θ符号 定义：若f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n))且f(n)=Ω(g(n))f(n)=\\Omega(g(n))f(n)=Ω(g(n))，则记作f(n)=Θ(g(n))f(n)=\\Theta(g(n))f(n)=Θ(g(n))。 举例： f(n)=n2+n,g(n)=100n2f(n)=n^2+n, g(n)=100n^2f(n)=n2+n,g(n)=100n2，那么有f(n)=Θ(g(n))f(n)=\\Theta(g(n))f(n)=Θ(g(n))。 注意： f(n)f(n)f(n)的阶与g(n)g(n)g(n)的阶相等； 对前面有限个nnn值可以不满足条件。 Big-O标记 O(1) 常量，运行时间和元素个数无关； O(log(n)) 对数，运行时间随元素个数的增加呈对数增长； O(n) 线性，运行时间随元素个数的增加呈线性增长； O(nlog(n)) n-log-n，运行时间随元素个数的增加呈“线性与对数的乘积”的增长； O(n^2) 二次方，运行时间随元素个数的增加呈平方增长。 Big-O标记隐藏（忽略）了指数较小的因子。","link":"/2020/05/13/%E7%AE%97%E6%B3%95%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-1/"},{"title":"冒号课堂笔记(5-6课)","text":"《冒泡课堂：编程范式与OOP思想》读书笔记 5-6 课 编程语言 Duck类型的哲学：名义不重要，重要的是能力。 鸭子类型是动态类型的一种风格，允许非继承性多态，即一个对象的类型可以由其接口集合来去定，不需要通过显示继承，有利于代码重用。由于Duck类型的接口组合是隐性的，其使用者须要比普通的interface更小心，以免误用；其维护者也要小心，以免破坏客户端代码；另外，它也可能造成滥用。 数据类型包含两个要素： 允许取值的集合 允许参与的运算 如int类型在Java中既定义了介于−231-2^{31}−231和231−12^{31}-1231−1之间的整数集合，也定义了该集合上的整数所能进行的运算。 限定一个变量的数据类型，就意味着限制该变量的取值范围和所参与的运算，这从一定程度上保证了代码的安全性。 数据类型既有针对机器的物理意义，又有针对人的逻辑意义。前者进行底层的内存分配和数值运算等，后者用于表达高层的逻辑概念。既然类型如此重要，类型检查就必不可少。 所谓动态类型语言（dynamic typing language），正是指类型检查发生在运行期间（run-time）的语言。 优点：代码灵活简明、易于重用，适合泛型编程和快速原型开发。 静态类型语言（static typing language）是类型检查发生在运行之前（包括编译期间，compile-time）的语言。 优点：运行之前的类型检查增强了代码的可靠性，使编译器有可能进行优化处理而提高运行效率，节省了运行期的类型检查所占用的时间和空间，同时类型声明有辅助文档的功效。 动态类型的变量不需要显示声明，静态类型的变量需要通过显示声明或类型推断。 类型的动静与强弱完全是正交的两个概念。静态类型语言中，有强类型的Java，也有弱类型的C；动态类型语言中，有强类型的Smalltalk，也有弱类型的JavaScript。前者通过类型的绑定时间来划分，后者以类型的约束强度来划分。 通常弱类型语言（weakly-typed language）允许一种类型的值隐性转化为另一种类型。 类型按安全性来划分，可分为类型安全（type-safe language）和类型不安全语言（type-unsafe language）。 类型检查的目的就是为了避免类型错误（type error），即杜绝因类型问题而产生的错误或不良代码。 弱类型语言允许类型的隐性转化，被认为是类型不安全的；而强类型的语言则不允许这种转化，被认为是类型安全的。 静态类型检查实行“疑罪从有”的有罪推定制，动态类型检查实行“疑罪从无”的无罪推定制。取舍原则是：Static Typing Where Possible, Dynamic Typing When Needed。即尽可能守规则，必要时变通。 脚本语言一般是解释型语言，不需要通过“编译 - 链接 - 运行”的循环圈，便利快捷，加之简单宽松的语法、面向字符的特性，以及较强的文本处理能力，尤其适合作为年和语言，多用于系统管理和集成。 动态语言秉承的理念：优化人的时间而不是机器的时间。为提高人的生产效率，宁肯牺牲部分程序性能或者购买更高配置的硬件。 动态语言在程序运行期间改变数据结构、函数定义、对象行为或指令流程等，相比静态语言在结构和功能上的更就有动态性。 优点： 代码量少，从一定程度上减轻了维护难度； 提供字节码编译或JIT编译，弥补了运行效率上的不足； 一些模块的结构和功能上的变化不会导致相关模块的重新编译和链接； 具有灵活、适应力强和开发周期短的特点，能够快速响应客户端的需求变化，并且适合快速原型开发。 C++提倡使用RAII原则解决包括内存在内的资源管理问题。RRIF（Resource Release Is Finalization），即“资源释即终结化”，其思想是：将资源的取放与某一对象的生命周期绑定，初始化对象是获取资源，终结化对象时释放资源。用户代码不再直接管理资源，只需控制相应对象即可。这样代码得以简化，资源的有效性也得以保障，并且还是异常安全的（exception-safe）。","link":"/2020/06/10/%E5%86%92%E5%8F%B7%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0-5-6/"},{"title":"SystemTap学习记录","text":"SystemTap 工具 SystemTap 允许用户在不重新编译代码的情况下利用静态追踪、动态追踪工具，比如在任何地方动态插入printk，或者改变内核的关键数据结构（guru模式）。所有的操作都要以root用户模式下进行。 安装 1$ sudo apt install systemtap systemtap-runtime 安装kernel debug symbol 1234567891011121314# 16.04 或更高$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C8CAB6595FDFF622 # 旧版本$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys ECDCAD72428D7C01 $ codename=$(lsb_release -c | awk &apos;{print $2}&apos;)$ sudo tee /etc/apt/sources.list.d/ddebs.list &lt;&lt; EOFdeb http://ddebs.ubuntu.com/ ${codename} main restricted universe multiversedeb http://ddebs.ubuntu.com/ ${codename}-security main restricted universe multiversedeb http://ddebs.ubuntu.com/ ${codename}-updates main restricted universe multiversedeb http://ddebs.ubuntu.com/ ${codename}-proposed main restricted universe multiverseEOF$ sudo apt-get update$ sudo apt-get install linux-image-$(uname -r)-dbgsym 基础 类 Awk/C 语言 可以嵌入到C语言中（guru 模式） SystemTap Language Reference 指令 限制 SystemTap 可以在内核空间进行追踪，但在用户空间追踪事件取决于内核的支持（Utrace机制） 没有内置于内核中，所以性能比eBPF稍差。 示例 ¶ apps/gmalloc_watch.stp - Tracing glib2 memory allocations The gmalloc_watch.stp script from Colin Walters&apos; blog traces the allocation of glib2 memory using the markers in glib2. 1# stap gmalloc_watch.stp -T 1 ¶ memory/glibc-malloc.stp - Overview glibc malloc internal operations This script reports on internal statistics of the glibc malloc implementation, as used by a process restricted by stap -x/-c 1# stap glibc-malloc.stp -c &apos;stap --dump-functions&apos; ¶ memory/numa_faults.stp - Summarize Process Misses across NUMA Nodes The numa_faults.stp script tracks the read and write pages faults for each process. When the script exits it prints out the total read and write pages faults for each process. The script also provide a break down of page faults per node for each process. This script is useful for determining whether the program has good locality (page faults limited to a single node) on a NUMA computer. sample usage in memory/numa_faults.txt …… 火焰图 http://www.brendangregg.com/FlameGraphs/memoryflamegraphs.html 参考 Ubuntu - Systemtap SystemTap man SystemTap Tutorial SystemTap Beginners Guide SystemTap Example FlameGraph","link":"/2020/06/13/SystemTap%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"title":"Huge Page","text":"Ⅰ. Check Huge Page Linux 内核支持多种 page size。 架构 HugePage Size arm64 4K, 2M and 1G (or 64K and 512M if one builds their own kernel with CONFIG_ARM64_64K_PAGES=y) x86 4K and 4M (2M in PAE mode，1GB if architecturally supported) amd64 2MB, 1GB ia64 4K, 8K, 64K, 256K, 1M, 4M, 16M, 256M ppc64 4K, 16M Huge Page 支持 mmap 和 shmget、shmat 调用。 当前系统 Huge Page 设置信息 123456789$ grep Huge /proc/meminfo AnonHugePages: 0 kBShmemHugePages: 0 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBHugetlb: 0 kB HugePages_Total Huge Page 池的页面数量。 HugePages_Free Huge Page 池中未分配的页面数量。 HugePages_Rsvd 已承诺从池中分配但尚未进行分配的 Huge Page 的数量。 HugePages_Surp /proc/sys/vm/nr_hugepages中 表示 Huge Page 池中页面数量。 /proc/sys/vm/nr_overcommit_hugepages 表示最大值。 Hugepagesize 默认 hugepage 尺寸（Kb）。 Hugetlb 内存总量（kB） HugePages_Total * Hugepagesize /proc/filesystems 可以查看 hugetlbfs 配置信息 /proc/sys/vm/nr_hugepages 表示当前内核大页面池中“持久”大页面的数量。 检查 NUMA 系统中大型页面的每个节点分布情况，使用： 1cat /sys/devices/system/node/node*/meminfo | fgrep Huge Shirink： Shrinking the persistent huge page pool via nr_hugepages such that it becomes less than the number of huge pages in use will convert the balance of the in-use huge pages to surplus huge pages. This will occur even if the number of surplus pages it would exceed the overcommit value. As long as this condition holds--that is, until nr_hugepages+nr_overcommit_hugepages is increased sufficiently, or the surplus huge pages go out of use and are freed -- no more surplus huge pages will be allowed to be allocated. 运行时 huge page 接口 /proc/sys/vm /sys/kernel/mm/hugepages 中 hugepages-${size}kB Ⅱ、Huge Page 分配/释放与 NUMA 内存策略 分配或释放 huge page 可以使用： 1numactl -m &lt;node-list&gt; echo 20 &gt;/proc/sys/vm/nr_hugepages_mempolicy 这个操作将会释放或分配 abs(20 - nr_hugepages) 到 &lt;node-list&gt; 。 Ⅲ、使用 Huge Page 需要使用 mmap ，应该先挂载 hugetlbfs： 123 mount -t hugetlbfs \\-o uid=&lt;value&gt;,gid=&lt;value&gt;,mode=&lt;value&gt;,pagesize=&lt;value&gt;,size=&lt;value&gt;,\\min_size=&lt;value&gt;,nr_inodes=&lt;value&gt; none /mnt/huge 在内核 2.6 之后，可以使用 MAP_HUGETLB 的方式操作内存。 map_hugetlb hugepage-shm hugepage-mmaphttps://man7.org/linux/man-pages/man2/mmap.2.html libhugetlbfs 测试 设置 huge page 12345678910sysctl vm.nr_hugepages=192AnonHugePages: 0 kBShmemHugePages: 0 kBHugePages_Total: 192HugePages_Free: 192HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBHugetlb: 393216 kB huge.c 测试 123456789101112131415161718192021222324#include &lt;sys/mman.h&gt;#include &lt;stdio.h&gt;#include &lt;memory.h&gt;int main(int argc, char *argv[]) { char *m; size_t s = (8UL * 1024 * 1024); m = mmap(NULL, s, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | 0x40000 /*MAP_HUGETLB*/, -1, 0); if (m == MAP_FAILED) { perror(&quot;map mem&quot;); m = NULL; return 1; } memset(m, 0, s); printf(&quot;map_hugetlb ok, press ENTER to quit!\\n&quot;); getchar(); munmap(m, s); return 0;} 查看 huge page 信息 1234567891011121314$ gcc huge.c$ ./a.out map_hugetlb ok, press ENTER to quit!$ cat /proc/meminfo |grep -i hugeAnonHugePages: 0 kBShmemHugePages: 0 kBHugePages_Total: 192HugePages_Free: 188HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBHugetlb: 393216 kB Reference https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt http://blog.chinaunix.net/uid-28541347-id-5783934.html https://wiki.debian.org/Hugepages Linux下试验大页面映射（MAP_HUGETLB）_cncnlg的专栏-CSDN博客_map_hugetlb https://www.kernel.org/doc/Documentation/vm/transhuge.txt mmap(2) - Linux manual page","link":"/2020/08/11/HugePage/"},{"title":"学习流行歌曲曲目","text":"难度逐级升高！ 如何学习演唱流行歌曲 首先找到准备好学唱歌曲的歌词，反复阅读 分析、了解歌词中表达的情感状态，并用对应的情感状态学唱 反复聆听原唱 5 ~ 10 遍 小声跟唱直到鞥能够大体跟得上歌曲节奏和旋律 不清晰的节奏或旋律，多听几遍 对旋律和节奏掌握不好的，对照曲谱跟唱 分析歌手演唱技巧，注意学习应用 旋律和节奏大体掌握后，跟伴奏练唱 跟伴奏练习的时候，如遇到不熟悉的地方反复聆听原唱 伴奏中的人声伴唱一般不是主旋律，是主旋律的和声 使用录歌软件录下来，对比聆听 不要带着耳机演唱（容易跑调，最多戴一只耳机） 男声一级 《一次就好 》杨宗纬 《中国人》刘德华 《爱我别走》张震岳 《心如刀割》张学友 《爱情转移》陈奕迅    《十年》陈奕迅 《爱一个人好难》苏永康 《眼泪》张学友 《风雨无阻》周华健 《把根留住》童安格 《东方之珠》 李克勤 《忘情水》刘德华 《夜半小夜曲》李克勤 《知足》五月天 《稻香》 周杰伦 《水星记》郭顶 《消愁》 毛不易 《别再闹了》毛不易 男声二级 《告白气球》 周杰伦 《一生有你》水木年华 《吻别》 张学友 《蓝莲花》许巍 《彩虹》周杰伦 《暗香》 沙宝亮 《愿得一人心》李行亮 《温柔》 五月天 《说谎》林宥嘉 《刚刚好》薛之谦 《末班车》萧煌奇 《在此》韩磊 《Take me to your heart》 迈克学摇滚 《等你下课》周杰伦 《青花瓷》周杰伦 《天后》 陈势安 男声三级 《我爱你中国》汪峰 《卓玛》 亚东 《你是我的眼》萧煌奇 《过火》张信哲 《单身情歌》林志炫 《精忠报国》屠洪刚 《悟空》戴荃 《同桌的你》老狼 《他说》林俊杰 《我们不一样》大壮 《父亲的草原母亲的河》 布仁巴雅尔 《You raise me up》 Westlife","link":"/2020/09/08/%E6%B5%81%E8%A1%8C%E6%AD%8C%E6%9B%B2%E6%9B%B2%E7%9B%AE/"},{"title":"图的存储与算法","text":"图论作为数学领域的重要分支已经有数百年的历史。图论应用的领域广泛，包括了地图、网页信息、电路、任务调度、商业交易、计算机网络和社交网络等。 图的类型 图是由一组顶点和一组能够将两个顶点相连的边组成的。 图有4种重要的模型：无向图（简单连接）、有向图（连接有方向性）、加权图（连接带有权值）和加权有向图（连接既有方向性又带有权值）。 特殊的图： 特殊的图 自环，即一条连接一个顶点和其自身的边 连接同一对顶点的两条边称为平行边。 术语 在图中，路径是由边顺序连接的一系列顶点。简单路径是一条没有重复顶点的路径。环是一条至少含有一条边且起点和终点相同的路径。简单环是一条（除了起点和终点必须相同之外）不含有重复顶点和边的环。路径或者环的长度为其所包含的边数。 如果从任意一个顶点都存在一条路径到达另一条任意顶点，我们称这幅图为连通图。一副非连通图的图由若干连通部分组成，他们都是其极大连通子图。 树是一副无环连通图。互不相连的树组成的集合叫做森林。连通图的生成树是它的一副子图，它含有图中所有的顶点且是一棵树。图的生成森林是它的所有连通子图的生成树的集合。 树 图的密度是指已经连接的顶点对占所有可能被连接的顶点对的比例。在稀疏图中，被连接的顶点对很少；而在稠密图中，只有少部分顶点之间没有边连接。 二分图是一种能够将所有结点分为两部分的图，其中图的每条边所连接的两个顶点都分别属于不同的部分。 图的存储 图存储的要求： 它必须为可能在应用中碰到的各种类型的图预留出足够的空间； Graph的实例方法的实现一定要快——它们是开发处理图的各种用例的基础。 图数据的存储方式有以下几种： 邻接矩阵 使用V×VV \\times VV×V的布尔矩阵，当顶点v 和顶点w之间有相连接的边时，定义v行w列元素值为true，否则为false。优点是实现简单，缺点是空间复杂度高，为V2V^2V2。 邻接表（链式存储） 以顶点为索引的列表数组，其中每个元素都对应一条链表，其中每个元素都是和该顶点相邻的顶点列表。 边集数组 使用Edge类，它含有两个int实例变量。这种表示方法简洁但不满足第二个条件，实现adj()需要检查所有的边。 前向星 链式前向星 性能复杂度 数据结构 所需空间 添加一条边v→w 检查w和v是否相邻 遍历v的所有相邻顶点 边的列表 EEE 111 EEE EEE 邻接矩阵 V2V^2V2 111 111 VVV 邻接表 E+VE+VE+V 111 degree(v)degree(v)degree(v) degree(v)degree(v)degree(v) 邻接集 E+VE+VE+V log⁡V\\log{V}logV log⁡V\\log{V}logV log⁡V+degree(v)\\log{V}+degree(v)logV+degree(v) 图的数据类型 相关API class Graph Graph(int V) 创建一个含有V个顶点但不含有边的图 Graph(In in) 从标准输入流in读入一幅图 int V() 顶点数 int E() 边数 void addEdge(int v, int w) 向图中添加一条边v→w Itereable&lt;Integer&gt; adj(v) 和v相邻的所有顶点 String toString() 对象的字符串表示 toString()方法和adj()方法用来允许用例遍历给定顶点的所有相邻顶点（遍历顺序不确定）。 伪代码 计算v的度数 12345int degree(Graph G, int v) { int degree = 0; for (int w: G.adj(v)) degree++; return degree;} 计算所有顶点的最大度数 123456789int maxDegree(Graph G) { int max = 0; for (auto v = 0; v &lt; G.V();v++) { if (degree(G, v) &gt; max) { max = degree(G, v); } } return max;} 计算所有顶点的平均度数 123double avgDegree(Graph G) { return 2 * G.E() / G.V();} 计算自环的个数 123456789int numberOfSelfLoops(Graph G) { int count = 0; for (auto v=0; v&lt;G.V(); v++) { for (const auto w: G.adj()) { int (v == w) count++; } } return count/2; // 每条边被记过两次} 图的邻接表的字符串表示（Graph的实例方法） 1234567891011std::string toString() { std::string s = V + &quot; vertices, &quot; + E + &quot; edges\\n&quot;; for (auto v=0; v&lt;V; v++) { s += v + &quot;: &quot;; for (const auto w: adj(v)) { s += w + &quot; &quot;; } s += &quot;\\n&quot;; } return s;} 图的相关算法 深度优先搜索 广度优先搜索 参考 https://zhuanlan.zhihu.com/p/215384586 《算法》","link":"/2020/10/26/%E5%9B%BE%E7%9A%84%E7%9B%B8%E5%85%B3/"},{"title":"Python的LRU Cache","text":"functools.lru_cache 在 Python 中的 functools 模块是应用高阶函数，即参数或（和）返回值为其他函数的函数。通常来说，此模块的功能适用于所有可调用对象。 12345678910@functools.cachedef factorial(n): return n * factorial(n-1) if n else 1&gt;&gt;&gt; factorial(10) # no previously cached result, makes 11 recursive calls3628800&gt;&gt;&gt; factorial(5) # just looks up cached value result120&gt;&gt;&gt; factorial(12) # makes two new recursive calls, the other 10 are cached479001600 functools.cache(user_function) 是简单轻量级未绑定函数缓存。 有时称为 &quot;memoize&quot;。返回值与 lru_cache(maxsize=None) 相同，创建一个查找函数参数的字典的简单包装器。 因为它不需要移出旧值，所以比带有大小限制的 lru_cache() 更小更快。` LRU函数的API是@functools.lru_cache(user_function) 和 @functools.lru_cache(maxsize=128, typed=False)，一个为函数提供缓存功能的装饰器，缓存maxsize组传入参数，在下次以相同参数调用时直接返回上一次的结果。用以节约高开销或I/O函数的调用时间。 由于使用了字典存储缓存，所以该函数的固定参数和关键字参数必须是可哈希的。不同模式的参数可能被视为不同从而产生多个缓存项，例如, f(a=1, b=2) 和 f(b=2, a=1) 因其参数顺序不同，可能会被缓存两次。 如果指定了user_function，它必须是一个可调用对象。 这允许 lru_cache 装饰器被直接应用于一个用户自定义函数，让 maxsize 保持其默认值 128: 1234@lru_cachedef count_vowels(sentence): sentence = sentence.casefold() return sum(sentence.count(vowel) for vowel in &apos;aeiou&apos;) 如果maxsize设为None，LRU 特性将被禁用且缓存可无限增长。 如果typed设置为true，不同类型的函数参数将被分别缓存。例如， f(3) 和 f(3.0) 将被视为不同而分别缓存。 被包装的函数配有一个cache_parameters()函数，该函数返回一个新的dict用来显示maxsize和typed的值。 这只是出于显示信息的目的。 改变值没有任何效果。 为了衡量缓存的有效性以便调整maxsize形参，被装饰的函数带有一个cache_info()函数。当调用cache_info()函数时，返回一个具名元组，包含命中次数 hits，未命中次数 misses ，最大缓存数量 maxsize 和 当前缓存大小 currsize。在多线程环境中，命中数与未命中数是不完全准确的。 该装饰器也提供了一个用于清理/使缓存失效的函数cache_clear() 。 原始的未经装饰的函数可以通过 __wrapped__ 属性访问。它可以用于检查、绕过缓存，或使用不同的缓存再次装饰原始函数。 LRU（最久未使用算法）缓存 在最近的调用是即将到来的调用的最佳预测值时性能最好（例如，新闻服务器上最热门文章倾向于每天更改）。 缓存的大小限制可确保缓存不会在长期运行进程如网站服务器上无限制地增长。 一般来说，LRU缓存只在当你想要重用之前计算的结果时使用。因此，用它缓存具有副作用的函数、需要在每次调用时创建不同、易变的对象的函数或者诸如time（）或random（）之类的不纯函数是没有意义的。 静态 Web 内容的 LRU 缓存示例： 12345678910111213141516@lru_cache(maxsize=32)def get_pep(num): &apos;Retrieve text of a Python Enhancement Proposal&apos; resource = &apos;http://www.python.org/dev/peps/pep-%04d/&apos; % num try: with urllib.request.urlopen(resource) as s: return s.read() except urllib.error.HTTPError: return &apos;Not Found&apos;&gt;&gt;&gt; for n in 8, 290, 308, 320, 8, 218, 320, 279, 289, 320, 9991:... pep = get_pep(n)... print(n, len(pep))&gt;&gt;&gt; get_pep.cache_info()CacheInfo(hits=3, misses=8, maxsize=32, currsize=8) 以下是使用缓存通过 动态规划 计算 斐波那契数列 的例子。 1234567891011@lru_cache(maxsize=None)def fib(n): if n &lt; 2: return n return fib(n-1) + fib(n-2)&gt;&gt;&gt; [fib(n) for n in range(16)][0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]&gt;&gt;&gt; fib.cache_info()CacheInfo(hits=28, misses=16, maxsize=None, currsize=16) Python中的实现 在 CPython 中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209################################################################################### LRU Cache function decorator################################################################################_CacheInfo = namedtuple(&quot;CacheInfo&quot;, [&quot;hits&quot;, &quot;misses&quot;, &quot;maxsize&quot;, &quot;currsize&quot;])class _HashedSeq(list): &quot;&quot;&quot; This class guarantees that hash() will be called no more than once per element. This is important because the lru_cache() will hash the key multiple times on a cache miss. &quot;&quot;&quot; __slots__ = &apos;hashvalue&apos; def __init__(self, tup, hash=hash): self[:] = tup self.hashvalue = hash(tup) def __hash__(self): return self.hashvaluedef _make_key(args, kwds, typed, kwd_mark = (object(),), fasttypes = {int, str}, tuple=tuple, type=type, len=len): &quot;&quot;&quot;Make a cache key from optionally typed positional and keyword arguments The key is constructed in a way that is flat as possible rather than as a nested structure that would take more memory. If there is only a single argument and its data type is known to cache its hash value, then that argument is returned without a wrapper. This saves space and improves lookup speed. &quot;&quot;&quot; # All of code below relies on kwds preserving the order input by the user. # Formerly, we sorted() the kwds before looping. The new way is *much* # faster; however, it means that f(x=1, y=2) will now be treated as a # distinct call from f(y=2, x=1) which will be cached separately. key = args if kwds: key += kwd_mark for item in kwds.items(): key += item if typed: key += tuple(type(v) for v in args) if kwds: key += tuple(type(v) for v in kwds.values()) elif len(key) == 1 and type(key[0]) in fasttypes: return key[0] return _HashedSeq(key)def lru_cache(maxsize=128, typed=False): &quot;&quot;&quot;Least-recently-used cache decorator. If *maxsize* is set to None, the LRU features are disabled and the cache can grow without bound. If *typed* is True, arguments of different types will be cached separately. For example, f(3.0) and f(3) will be treated as distinct calls with distinct results. Arguments to the cached function must be hashable. View the cache statistics named tuple (hits, misses, maxsize, currsize) with f.cache_info(). Clear the cache and statistics with f.cache_clear(). Access the underlying function with f.__wrapped__. See: http://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU) &quot;&quot;&quot; # Users should only access the lru_cache through its public API: # cache_info, cache_clear, and f.__wrapped__ # The internals of the lru_cache are encapsulated for thread safety and # to allow the implementation to change (including a possible C version). if isinstance(maxsize, int): # Negative maxsize is treated as 0 if maxsize &lt; 0: maxsize = 0 elif callable(maxsize) and isinstance(typed, bool): # The user_function was passed in directly via the maxsize argument user_function, maxsize = maxsize, 128 wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo) wrapper.cache_parameters = lambda : {&apos;maxsize&apos;: maxsize, &apos;typed&apos;: typed} return update_wrapper(wrapper, user_function) elif maxsize is not None: raise TypeError( &apos;Expected first argument to be an integer, a callable, or None&apos;) def decorating_function(user_function): wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo) wrapper.cache_parameters = lambda : {&apos;maxsize&apos;: maxsize, &apos;typed&apos;: typed} return update_wrapper(wrapper, user_function) return decorating_functiondef _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo): # Constants shared by all lru cache instances: sentinel = object() # unique object used to signal cache misses make_key = _make_key # build a key from the function arguments PREV, NEXT, KEY, RESULT = 0, 1, 2, 3 # names for the link fields cache = {} hits = misses = 0 full = False cache_get = cache.get # bound method to lookup a key or return None cache_len = cache.__len__ # get cache size without calling len() lock = RLock() # because linkedlist updates aren&apos;t threadsafe root = [] # root of the circular doubly linked list root[:] = [root, root, None, None] # initialize by pointing to self if maxsize == 0: def wrapper(*args, **kwds): # No caching -- just a statistics update nonlocal misses misses += 1 result = user_function(*args, **kwds) return result elif maxsize is None: def wrapper(*args, **kwds): # Simple caching without ordering or size limit nonlocal hits, misses key = make_key(args, kwds, typed) result = cache_get(key, sentinel) if result is not sentinel: hits += 1 return result misses += 1 result = user_function(*args, **kwds) cache[key] = result return result else: def wrapper(*args, **kwds): # Size limited caching that tracks accesses by recency nonlocal root, hits, misses, full key = make_key(args, kwds, typed) with lock: link = cache_get(key) if link is not None: # Move the link to the front of the circular queue link_prev, link_next, _key, result = link link_prev[NEXT] = link_next link_next[PREV] = link_prev last = root[PREV] last[NEXT] = root[PREV] = link link[PREV] = last link[NEXT] = root hits += 1 return result misses += 1 result = user_function(*args, **kwds) with lock: if key in cache: # Getting here means that this same key was added to the # cache while the lock was released. Since the link # update is already done, we need only return the # computed result and update the count of misses. pass elif full: # Use the old root to store the new key and result. oldroot = root oldroot[KEY] = key oldroot[RESULT] = result # Empty the oldest link and make it the new root. # Keep a reference to the old key and old result to # prevent their ref counts from going to zero during the # update. That will prevent potentially arbitrary object # clean-up code (i.e. __del__) from running while we&apos;re # still adjusting the links. root = oldroot[NEXT] oldkey = root[KEY] oldresult = root[RESULT] root[KEY] = root[RESULT] = None # Now update the cache dictionary. del cache[oldkey] # Save the potentially reentrant cache[key] assignment # for last, after the root and links have been put in # a consistent state. cache[key] = oldroot else: # Put result in a new link at the front of the queue. last = root[PREV] link = [last, root, key, result] last[NEXT] = root[PREV] = cache[key] = link # Use the cache_len bound method instead of the len() function # which could potentially be wrapped in an lru_cache itself. full = (cache_len() &gt;= maxsize) return result def cache_info(): &quot;&quot;&quot;Report cache statistics&quot;&quot;&quot; with lock: return _CacheInfo(hits, misses, maxsize, cache_len()) def cache_clear(): &quot;&quot;&quot;Clear the cache and cache statistics&quot;&quot;&quot; nonlocal hits, misses, full with lock: cache.clear() root[:] = [root, root, None, None] hits = misses = 0 full = False wrapper.cache_info = cache_info wrapper.cache_clear = cache_clear return wrappertry: from _functools import _lru_cache_wrapperexcept ImportError: pass 此外，@cache 函数就是@lru_cache参数memoize设置为None。 1234567################################################################################### cache -- simplified access to the infinity cache################################################################################def cache(user_function, /): &apos;Simple lightweight unbounded cache. Sometimes called &quot;memoize&quot;.&apos; return lru_cache(maxsize=None)(user_function) methodtools中对lru_cache的修饰 123456789101112131415161718192021222324252627282930313233343536373839404142import functoolsfrom wirerope import Wire, WireRope__version__ = &apos;0.4.2&apos;__all__ = &apos;lru_cache&apos;,if hasattr(functools, &apos;lru_cache&apos;): _functools_lru_cache = functools.lru_cacheelse: try: import functools32 except ImportError: # raise AttributeError about fallback failure functools.lru_cache # install `functools32` to run on py2 else: _functools_lru_cache = functools32.lru_cacheclass _LruCacheWire(Wire): def __init__(self, rope, *args, **kwargs): super(_LruCacheWire, self).__init__(rope, *args, **kwargs) lru_args, lru_kwargs = rope._args wrapper = _functools_lru_cache( *lru_args, **lru_kwargs)(self.__func__) self.__call__ = wrapper self.cache_clear = wrapper.cache_clear self.cache_info = wrapper.cache_info def __call__(self, *args, **kwargs): # descriptor detection support - never called return self.__call__(*args, **kwargs) def _on_property(self): return self.__call__()@functools.wraps(_functools_lru_cache)def lru_cache(*args, **kwargs): return WireRope(_LruCacheWire, wraps=True, rope_args=(args, kwargs)) 参考 https://github.com/youknowone/methodtools https://github.com/python/cpython/tree/3.9 https://realpython.com/lru-cache-python/ [Wirerope](https://github.com/youknowone/wirerope）","link":"/2020/12/30/Python%E7%9A%84LRU-Cache/"}],"tags":[{"name":"DSL","slug":"DSL","link":"/tags/DSL/"},{"name":"image processing","slug":"image-processing","link":"/tags/image-processing/"},{"name":"图像处理","slug":"图像处理","link":"/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"Pin","slug":"Pin","link":"/tags/Pin/"},{"name":"社会计算","slug":"社会计算","link":"/tags/%E7%A4%BE%E4%BC%9A%E8%AE%A1%E7%AE%97/"},{"name":"计算思维","slug":"计算思维","link":"/tags/%E8%AE%A1%E7%AE%97%E6%80%9D%E7%BB%B4/"},{"name":"小世界问题","slug":"小世界问题","link":"/tags/%E5%B0%8F%E4%B8%96%E7%95%8C%E9%97%AE%E9%A2%98/"},{"name":"博弈论","slug":"博弈论","link":"/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/"},{"name":"有向图","slug":"有向图","link":"/tags/%E6%9C%89%E5%90%91%E5%9B%BE/"},{"name":"网页排序","slug":"网页排序","link":"/tags/%E7%BD%91%E9%A1%B5%E6%8E%92%E5%BA%8F/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"javascript","slug":"javascript","link":"/tags/javascript/"},{"name":"GPU","slug":"GPU","link":"/tags/GPU/"},{"name":"pip","slug":"pip","link":"/tags/pip/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"pypi","slug":"pypi","link":"/tags/pypi/"},{"name":"编程范式","slug":"编程范式","link":"/tags/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/"},{"name":"决策论","slug":"决策论","link":"/tags/%E5%86%B3%E7%AD%96%E8%AE%BA/"},{"name":"运筹学","slug":"运筹学","link":"/tags/%E8%BF%90%E7%AD%B9%E5%AD%A6/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"算法与数据结构","slug":"算法与数据结构","link":"/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"algorithms","slug":"algorithms","link":"/tags/algorithms/"},{"name":"data structure","slug":"data-structure","link":"/tags/data-structure/"},{"name":"SystemTap","slug":"SystemTap","link":"/tags/SystemTap/"},{"name":"Huge Page","slug":"Huge-Page","link":"/tags/Huge-Page/"},{"name":"流行歌曲","slug":"流行歌曲","link":"/tags/%E6%B5%81%E8%A1%8C%E6%AD%8C%E6%9B%B2/"},{"name":"演唱","slug":"演唱","link":"/tags/%E6%BC%94%E5%94%B1/"},{"name":"图","slug":"图","link":"/tags/%E5%9B%BE/"},{"name":"lru","slug":"lru","link":"/tags/lru/"},{"name":"functools","slug":"functools","link":"/tags/functools/"}],"categories":[{"name":"编程","slug":"编程","link":"/categories/%E7%BC%96%E7%A8%8B/"},{"name":"图象处理","slug":"图象处理","link":"/categories/%E5%9B%BE%E8%B1%A1%E5%A4%84%E7%90%86/"},{"name":"OS","slug":"OS","link":"/categories/OS/"},{"name":"社会计算","slug":"社会计算","link":"/categories/%E7%A4%BE%E4%BC%9A%E8%AE%A1%E7%AE%97/"},{"name":"计算机性能","slug":"OS/计算机性能","link":"/categories/OS/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%80%A7%E8%83%BD/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"Javascript","slug":"Javascript","link":"/categories/Javascript/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"运筹学","slug":"运筹学","link":"/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/"},{"name":"WebGPU","slug":"Javascript/WebGPU","link":"/categories/Javascript/WebGPU/"},{"name":"Linux","slug":"OS/Linux","link":"/categories/OS/Linux/"},{"name":"生活","slug":"生活","link":"/categories/%E7%94%9F%E6%B4%BB/"},{"name":"functools","slug":"Python/functools","link":"/categories/Python/functools/"}]}